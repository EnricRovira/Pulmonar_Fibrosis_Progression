{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Corrupted CT Scans\n",
    "\n",
    "This Script is only needed in case gdcm extension fails you on local machine, if you have troubles installing gdcm in your local machine run this script on [Google Colab](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2020-08-22T14:46:15.407544Z",
     "iopub.status.busy": "2020-08-22T14:46:15.406649Z",
     "iopub.status.idle": "2020-08-22T14:47:40.352699Z",
     "shell.execute_reply": "2020-08-22T14:47:40.351712Z"
    },
    "papermill": {
     "duration": 84.964239,
     "end_time": "2020-08-22T14:47:40.352885",
     "exception": false,
     "start_time": "2020-08-22T14:46:15.388646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n",
      "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /opt/conda\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - gdcm\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    conda-4.8.4                |   py37hc8dfbb8_2         3.1 MB  conda-forge\r\n",
      "    gdcm-2.8.9                 |   py37h71b2a6d_0         3.4 MB  conda-forge\r\n",
      "    libjpeg-turbo-2.0.3        |       h516909a_1        1022 KB  conda-forge\r\n",
      "    openssl-1.1.1g             |       h516909a_1         2.1 MB  conda-forge\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:         9.6 MB\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  gdcm               conda-forge/linux-64::gdcm-2.8.9-py37h71b2a6d_0\r\n",
      "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-2.0.3-h516909a_1\r\n",
      "\r\n",
      "The following packages will be UPDATED:\r\n",
      "\r\n",
      "  conda                                4.8.3-py37hc8dfbb8_1 --> 4.8.4-py37hc8dfbb8_2\r\n",
      "  openssl                                 1.1.1g-h516909a_0 --> 1.1.1g-h516909a_1\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "openssl-1.1.1g       | 2.1 MB    | ##################################### | 100% \r\n",
      "libjpeg-turbo-2.0.3  | 1022 KB   | ##################################### | 100% \r\n",
      "conda-4.8.4          | 3.1 MB    | ##################################### | 100% \r\n",
      "gdcm-2.8.9           | 3.4 MB    | ##################################### | 100% \r\n",
      "Preparing transaction: - \b\bdone\r\n",
      "Verifying transaction: | \b\b/ \b\b- \b\bdone\r\n",
      "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge gdcm -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-22T14:47:40.639565Z",
     "iopub.status.busy": "2020-08-22T14:47:40.638643Z",
     "iopub.status.idle": "2020-08-22T14:47:43.262186Z",
     "shell.execute_reply": "2020-08-22T14:47:43.261465Z"
    },
    "papermill": {
     "duration": 2.769363,
     "end_time": "2020-08-22T14:47:43.262329",
     "exception": false,
     "start_time": "2020-08-22T14:47:40.492966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 01. Libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(12)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage import measure, morphology, segmentation, color\n",
    "import pydicom\n",
    "import imageio\n",
    "from joblib import parallel_backend, Parallel, delayed\n",
    "import PIL\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 02. Global Variables\n",
    "\n",
    "path = '../01_Data/'\n",
    "\n",
    "path_imgs_train = path + '/train/'\n",
    "path_imgs_test = path + '/test/'\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-22T14:47:43.559157Z",
     "iopub.status.busy": "2020-08-22T14:47:43.558246Z",
     "iopub.status.idle": "2020-08-22T14:47:44.702152Z",
     "shell.execute_reply": "2020-08-22T14:47:44.702707Z"
    },
    "papermill": {
     "duration": 1.303268,
     "end_time": "2020-08-22T14:47:44.702903",
     "exception": false,
     "start_time": "2020-08-22T14:47:43.399635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 7672.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 5040.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 -> There are 176 train unique patients\n",
      "1.2 -> There are 5 test unique patients\n",
      "No. of Train Images : 176\n",
      "No. of Test Images : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# 03. Load Data & Preprocess Data\n",
    "\n",
    "df_train = pd.read_csv(path + 'train.csv')\n",
    "df_test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "print(f'1.1 -> There are {df_train.Patient.unique().shape[0]} train unique patients')\n",
    "print(f'1.2 -> There are {df_test.Patient.unique().shape[0]} test unique patients')\n",
    "\n",
    "train_paths = glob.glob(path_imgs_train + '*')\n",
    "test_paths = glob.glob(path_imgs_test + '*')\n",
    "      \n",
    "print(f'No. of Train Images : {len(train_paths)}')\n",
    "print(f'No. of Test Images : {len(test_paths)}')\n",
    "      \n",
    "unique_train_patients = df_train.Patient.unique()\n",
    "unique_test_patients = df_test.Patient.unique()\n",
    "\n",
    "dict_train_patients_paths = {patient: path_imgs_train + patient + '/' for patient in unique_train_patients}\n",
    "dict_test_patients_paths = {patient: path_imgs_test + patient + '/' for patient in unique_test_patients}\n",
    "\n",
    "for patient in tqdm(dict_train_patients_paths):\n",
    "    list_files = os.listdir(dict_train_patients_paths[patient])\n",
    "    list_files = [dict_train_patients_paths[patient] + file for file in list_files]\n",
    "    dict_train_patients_paths[patient] = list_files\n",
    "    \n",
    "for patient in tqdm(dict_test_patients_paths):\n",
    "    list_files = os.listdir(dict_test_patients_paths[patient])\n",
    "    list_files = [dict_test_patients_paths[patient] + file for file in list_files]\n",
    "    dict_test_patients_paths[patient] = list_files\n",
    "    \n",
    "    \n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-22T14:47:45.027920Z",
     "iopub.status.busy": "2020-08-22T14:47:45.004141Z",
     "iopub.status.idle": "2020-08-22T14:47:45.064990Z",
     "shell.execute_reply": "2020-08-22T14:47:45.064146Z"
    },
    "papermill": {
     "duration": 0.218864,
     "end_time": "2020-08-22T14:47:45.065134",
     "exception": false,
     "start_time": "2020-08-22T14:47:44.846270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 04. Global Functions\n",
    "\n",
    "def loadSlices(patient_files):\n",
    "    slices = [pydicom.read_file(s) for s in patient_files]\n",
    "    slices.sort(key = lambda x: float(x.InstanceNumber))\n",
    "        \n",
    "    try:\n",
    "        slice_thickness = np.abs(slices[0].ImagePositionPatient[2] - slices[1].ImagePositionPatient[2])\n",
    "    except:\n",
    "        try:\n",
    "            slice_thickness = np.abs(slices[0].SliceLocation - slices[1].SliceLocation)\n",
    "        except:\n",
    "            slice_thickness = slices[0].SliceThickness\n",
    "            slices[0].RescaleIntercept = 1024\n",
    "    \n",
    "    if slice_thickness == 0:\n",
    "        slice_thickness = 1\n",
    "        \n",
    "    for s in slices:\n",
    "        s.SliceThickness = slice_thickness\n",
    "        \n",
    "    return slices\n",
    "\n",
    "\n",
    "def getPixelsHu(patient_scans):\n",
    "    patient_images = []\n",
    "    for s in patient_scans:\n",
    "        if s.Columns != s.Rows:\n",
    "            crop_size = 512\n",
    "            s_crop_img = imCropCenter(s.pixel_array, crop_size, crop_size)\n",
    "            patient_images.append(s_crop_img)\n",
    "        else:\n",
    "            patient_images.append(s.pixel_array)\n",
    "\n",
    "    patient_images = np.asarray(patient_images).astype(np.int16)\n",
    "\n",
    "    # The intercept is usually -1024, so air is approximately 0\n",
    "    patient_images[patient_images == -2000] = 0\n",
    "    \n",
    "    # Convert to Hounsfield units (HU)\n",
    "    intercept = patient_scans[0].RescaleIntercept\n",
    "    slope = patient_scans[0].RescaleSlope\n",
    "        \n",
    "    if slope != 1:\n",
    "        patient_images = slope * patient_images.astype(np.float64)\n",
    "        patient_images = patient_images.astype(np.int16)\n",
    "\n",
    "    patient_images += np.int16(intercept)\n",
    "    patient_images = np.clip(patient_images, -2048, 3284)\n",
    "    return np.array(patient_images, dtype=np.int16)\n",
    "\n",
    "\n",
    "def plotHistogramPixelesHu(patient_images):\n",
    "    plt.hist(patient_images.flatten(), bins=50, color='c')\n",
    "    plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "    plt.ylabel\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plotSampleStack(stack, rows=6, cols=6, start_with=10, show_every=3, figsize=(12,12)):\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=figsize)\n",
    "    for i in range(rows*cols):\n",
    "        ind = start_with + i*show_every\n",
    "        ax[int(i/rows),int(i % rows)].set_title('slice %d' % ind)\n",
    "        ax[int(i/rows),int(i % rows)].imshow(stack[ind],cmap='gray')\n",
    "        ax[int(i/rows),int(i % rows)].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def resampleImages(image, scan, new_spacing=[1,1,1]):\n",
    "    # Determine current pixel spacing\n",
    "    spacing = [float(scan[0].SliceThickness), \n",
    "                float(scan[0].PixelSpacing[0]), \n",
    "                float(scan[0].PixelSpacing[1])]\n",
    "\n",
    "    spacing = np.array(spacing, dtype=np.float32)\n",
    "\n",
    "    resize_factor = spacing / new_spacing\n",
    "    new_real_shape = image.shape * resize_factor\n",
    "    new_shape = np.round(new_real_shape)\n",
    "    real_resize_factor = new_shape / image.shape\n",
    "    new_spacing = spacing / real_resize_factor\n",
    "    \n",
    "    image = ndimage.interpolation.zoom(image, real_resize_factor)\n",
    "    \n",
    "    return image, spacing\n",
    "\n",
    "\n",
    "def generateMarkers(image):\n",
    "    \"\"\"\n",
    "    Generates markers for a given image.\n",
    "    \n",
    "    Parameters: image\n",
    "    \n",
    "    Returns: Internal Marker, External Marker, Watershed Marker\n",
    "    \"\"\"\n",
    "    \n",
    "    #Creation of the internal Marker\n",
    "    marker_internal = image < -400\n",
    "    marker_internal = segmentation.clear_border(marker_internal)\n",
    "    marker_internal_labels = measure.label(marker_internal)\n",
    "    \n",
    "    areas = [r.area for r in measure.regionprops(marker_internal_labels)]\n",
    "    areas.sort()\n",
    "    \n",
    "    if len(areas) > 2:\n",
    "        for region in measure.regionprops(marker_internal_labels):\n",
    "            if region.area < areas[-2]:\n",
    "                for coordinates in region.coords:                \n",
    "                       marker_internal_labels[coordinates[0], coordinates[1]] = 0\n",
    "    \n",
    "    marker_internal = marker_internal_labels > 0\n",
    "    \n",
    "    # Creation of the External Marker\n",
    "    external_a = ndimage.binary_dilation(marker_internal, iterations=10)\n",
    "    external_b = ndimage.binary_dilation(marker_internal, iterations=55)\n",
    "    marker_external = external_b ^ external_a\n",
    "    \n",
    "    # Creation of the Watershed Marker\n",
    "    marker_watershed = np.zeros(image.shape, dtype=np.int)\n",
    "    marker_watershed += marker_internal * 255\n",
    "    marker_watershed += marker_external * 128\n",
    "    \n",
    "    return marker_internal, marker_external, marker_watershed\n",
    "\n",
    "\n",
    "def seperateLungs(image, n_iters=2):\n",
    "    \"\"\"\n",
    "    Segments lungs using various techniques.\n",
    "    \n",
    "    Parameters: image (Scan image)\n",
    "    \n",
    "    Returns: \n",
    "        - Segmented Lung\n",
    "        - Lung Filter\n",
    "        - Outline Lung\n",
    "        - Watershed Lung\n",
    "        - Sobel Gradient\n",
    "    \"\"\"\n",
    "    marker_internal, marker_external, marker_watershed = generateMarkers(image)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Creation of Sobel Gradient\n",
    "    '''\n",
    "    \n",
    "    # Sobel-Gradient\n",
    "    sobel_filtered_dx = ndimage.sobel(image, 1)\n",
    "    sobel_filtered_dy = ndimage.sobel(image, 0)\n",
    "    sobel_gradient = np.hypot(sobel_filtered_dx, sobel_filtered_dy)\n",
    "    sobel_gradient *= 255.0 / np.max(sobel_gradient)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Using the watershed algorithm\n",
    "    \n",
    "    \n",
    "    We pass the image convoluted by sobel operator and the watershed marker\n",
    "    to morphology.watershed and get a matrix matrix labeled using the \n",
    "    watershed segmentation algorithm.\n",
    "    '''\n",
    "    watershed = morphology.watershed(sobel_gradient, marker_watershed)\n",
    "    \n",
    "    '''\n",
    "    Reducing the image to outlines after Watershed algorithm\n",
    "    '''\n",
    "    outline = ndimage.morphological_gradient(watershed, size=(3,3))\n",
    "    outline = outline.astype(bool)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Black Top-hat Morphology:\n",
    "    \n",
    "    The black top hat of an image is defined as its morphological closing\n",
    "    minus the original image. This operation returns the dark spots of the\n",
    "    image that are smaller than the structuring element. Note that dark \n",
    "    spots in the original image are bright spots after the black top hat.\n",
    "    '''\n",
    "    \n",
    "    # Structuring element used for the filter\n",
    "    blackhat_struct = [[0, 0, 1, 1, 1, 0, 0],\n",
    "                       [0, 1, 1, 1, 1, 1, 0],\n",
    "                       [1, 1, 1, 1, 1, 1, 1],\n",
    "                       [1, 1, 1, 1, 1, 1, 1],\n",
    "                       [1, 1, 1, 1, 1, 1, 1],\n",
    "                       [0, 1, 1, 1, 1, 1, 0],\n",
    "                       [0, 0, 1, 1, 1, 0, 0]]\n",
    "    \n",
    "    blackhat_struct = ndimage.iterate_structure(blackhat_struct, n_iters)\n",
    "    \n",
    "    # Perform Black Top-hat filter\n",
    "    outline += ndimage.black_tophat(outline, structure=blackhat_struct)\n",
    "    outline += ndimage.black_tophat(outline, structure=blackhat_struct)\n",
    "    '''\n",
    "    Generate lung filter using internal marker and outline.\n",
    "    '''\n",
    "    lungfilter = np.bitwise_or(marker_internal, outline)\n",
    "    lungfilter = ndimage.morphology.binary_closing(lungfilter, structure=np.ones((5,5)), iterations=3)\n",
    "    \n",
    "    '''\n",
    "    Segment lung using lungfilter and the image.\n",
    "    '''\n",
    "    segmented = np.where(lungfilter == 1, image, -2000*np.ones(image.shape))\n",
    "    \n",
    "    return segmented, lungfilter, outline, watershed, sobel_gradient\n",
    "\n",
    "\n",
    "def imCropCenter(img, w, h):\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    img_width, img_height = img.size\n",
    "    left, right = (img_width - w) / 2, (img_width + w) / 2\n",
    "    top, bottom = (img_height - h) / 2, (img_height + h) / 2\n",
    "    left, top = round(max(0, left)), round(max(0, top))\n",
    "    right, bottom = round(min(img_width - 0, right)), round(min(img_height - 0, bottom))\n",
    "    return np.asarray(img.crop((left, top, right, bottom)))\n",
    "     \n",
    "    \n",
    "def imCropAround(img, xc, yc, w, h):\n",
    "    img_width, img_height = img.size  # Get dimensions\n",
    "    left, right = xc - w / 2, xc + w / 2\n",
    "    top, bottom = yc - h / 2, yc + h / 2\n",
    "    left, top = round(max(0, left)), round(max(0, top))\n",
    "    right, bottom = round(min(img_width - 0, right)), round(min(img_height - 0, bottom))\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-22T14:48:31.433899Z",
     "iopub.status.busy": "2020-08-22T14:48:31.428688Z",
     "iopub.status.idle": "2020-08-22T14:48:31.442109Z",
     "shell.execute_reply": "2020-08-22T14:48:31.441452Z"
    },
    "papermill": {
     "duration": 0.201807,
     "end_time": "2020-08-22T14:48:31.442259",
     "exception": false,
     "start_time": "2020-08-22T14:48:31.240452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 05. Save Masks\n",
    " \n",
    "def saveMasks(patient, dict_paths, path, center_crop_size=80):\n",
    "    try:\n",
    "        patient_files = dict_paths[patient]\n",
    "        patient_files = sorted(patient_files, key=lambda i: int(os.path.splitext(os.path.basename(i))[0]))\n",
    "        patient_slices = loadSlices(patient_files)\n",
    "        patient_images = getPixelsHu(patient_slices)\n",
    "        imgs_after_resamp, spacing = resampleImages(patient_images, patient_slices, [1,1,1])\n",
    "        patient_imgs = []\n",
    "        for idx in range(imgs_after_resamp.shape[0]):\n",
    "            patient_crop_img = im_crop_center(imgs_after_resamp[idx], 320, 320)\n",
    "            patient_segmented, _, _, _, _ = seperateLungs(patient_crop_img, n_iters=10)\n",
    "            patient_imgs.append(patient_segmented)\n",
    "            \n",
    "        patient_imgs = np.asarray(patient_imgs)\n",
    "        file_name = patient + '_imgs_' + '.npy'\n",
    "        if not os.path.exists(path + patient + '/'):\n",
    "            os.mkdir(path + patient + '/')\n",
    "        file_output = path + patient + '/' + file_name\n",
    "        np.save(file_output, patient_imgs)\n",
    "    except:\n",
    "        print(f'Patient {patient} failed')\n",
    "        pass\n",
    "    \n",
    "def saveScans(patient, dict_paths, path, center_crop_size=80):\n",
    "    try:\n",
    "        patient_files = dict_paths[patient]\n",
    "        patient_files = sorted(patient_files, key=lambda i: int(os.path.splitext(os.path.basename(i))[0]))\n",
    "        patient_slices = loadSlices(patient_files)\n",
    "        patient_images = getPixelsHu(patient_slices)\n",
    "        imgs_after_resamp, spacing = resampleImages(patient_images, patient_slices, [1,1,1])\n",
    "        patient_imgs = []\n",
    "        for idx in range(imgs_after_resamp.shape[0]):\n",
    "            patient_crop_img = im_crop_center(imgs_after_resamp[idx], 320, 320)\n",
    "            patient_imgs.append(patient_crop_img)\n",
    "            \n",
    "        patient_imgs = np.asarray(patient_imgs)\n",
    "        file_name = patient + '_imgs_' + '.npy'\n",
    "        if not os.path.exists(path + patient + '/'):\n",
    "            os.mkdir(path + patient + '/')\n",
    "        file_output = path + patient + '/' + file_name\n",
    "        np.save(file_output, patient_imgs)\n",
    "    except:\n",
    "        print(f'Patient {patient} failed')\n",
    "        pass\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Masks and Preprocessed Corrupted Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-22T14:48:31.797189Z",
     "iopub.status.busy": "2020-08-22T14:48:31.795901Z",
     "iopub.status.idle": "2020-08-22T15:16:00.084179Z",
     "shell.execute_reply": "2020-08-22T15:16:00.081171Z"
    },
    "papermill": {
     "duration": 1648.470114,
     "end_time": "2020-08-22T15:16:00.085267",
     "exception": false,
     "start_time": "2020-08-22T14:48:31.615153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:158: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:158: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# 06. Corrupt images\n",
    "\n",
    "corrupt_imgs = ['ID00011637202177653955184', 'ID00052637202186188008618']\n",
    "\n",
    "path_out = path + './train_masks/'\n",
    "if not os.path.exists(path_out):\n",
    "    os.mkdir(path_out)\n",
    "path_out = path + './test_masks/'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    \n",
    "num_processors = int(int(os.environ['NUMBER_OF_PROCESSORS']) * 0.8) + 1\n",
    "\n",
    "with parallel_backend('threading', n_jobs=4):\n",
    "    Parallel()(delayed(saveMasks)(patient, dict_train_patients_paths, path=path_out) for patient in corrupt_imgs)\n",
    "    \n",
    "    \n",
    "path_out = path + './train_imgs/'\n",
    "if not os.path.exists(path_out):\n",
    "    os.mkdir(path_out)\n",
    "path_out = path + './test_imgs/'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "    \n",
    "with parallel_backend('threading', n_jobs=4):\n",
    "    Parallel()(delayed(saveScans)(patient, dict_train_patients_paths, path=path_out) for patient in corrupt_imgs)\n",
    "    \n",
    "#########################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1856.98522,
   "end_time": "2020-08-22T15:17:07.272670",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-22T14:46:10.287450",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
