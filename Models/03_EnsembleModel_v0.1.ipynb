{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EncoderDecoder Sequence Fibrosis Progression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 01. Libraries\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "tf.keras.backend.clear_session()\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "# To allocate memory dynamically\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "# tf.config.experimental.enable_mlir_graph_optimization()\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers, constraints, initializers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "from Utils.utils import *\n",
    "from Utils.attention_layers import BahdanauAttention, ScaledDotProductAttention, GeneralAttention, VisualAttentionBlock\n",
    "from Utils.preprocess_scans import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy as sp\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 02. Global Variables\n",
    "\n",
    "path = '../../01_Data/'\n",
    "path_models = '../../05_Saved_Models/'\n",
    "\n",
    "path_train_masks = path + '/train_masks_fast_masks/'\n",
    "path_test_masks = path + '/test_masks_fast_masks/'\n",
    "\n",
    "path_scans_train = path + 'train/'\n",
    "path_scans_test = path + 'test/'\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 44105.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 4976.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 8823.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 5060.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 -> There are 176 train unique patients\n",
      "1.2 -> There are 5 test unique patients\n",
      "No. of Train Masks : 176\n",
      "No. of Test Masks : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "# 03. Load Data & Preprocess Data\n",
    "\n",
    "df_train = pd.read_csv( path + 'train.csv')\n",
    "df_test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "print(f'1.1 -> There are {df_train.Patient.unique().shape[0]} train unique patients')\n",
    "print(f'1.2 -> There are {df_test.Patient.unique().shape[0]} test unique patients')\n",
    "\n",
    "train_mask_paths = glob.glob(path_train_masks + '*')\n",
    "test_mask_paths = glob.glob(path_test_masks + '*')\n",
    "\n",
    "print(f'No. of Train Masks : {len(train_mask_paths)}')\n",
    "print(f'No. of Test Masks : {len(test_mask_paths)}')\n",
    "      \n",
    "unique_train_patients = df_train.Patient.unique()\n",
    "unique_test_patients = df_test.Patient.unique()\n",
    "\n",
    "train_patients = os.listdir(path_train_masks)\n",
    "test_patients = os.listdir(path_test_masks)\n",
    "\n",
    "dict_train_patients_masks_paths = {patient: path_train_masks + patient + '/' for patient in train_patients}\n",
    "dict_test_patients_masks_paths = {patient: path_test_masks + patient + '/' for patient in test_patients}\n",
    "\n",
    "dict_train_patients_scans_paths = {patient: path_scans_train + patient + '/' for patient in unique_train_patients}\n",
    "dict_test_patients_scans_paths = {patient: path_scans_test + patient + '/' for patient in unique_test_patients}\n",
    "\n",
    "for patient in tqdm(dict_train_patients_masks_paths):\n",
    "    list_files = os.listdir(dict_train_patients_masks_paths[patient])\n",
    "    list_files = [dict_train_patients_masks_paths[patient] + file for file in list_files]\n",
    "    dict_train_patients_masks_paths[patient] = list_files\n",
    "    \n",
    "for patient in tqdm(dict_test_patients_masks_paths):\n",
    "    list_files = os.listdir(dict_test_patients_masks_paths[patient])\n",
    "    list_files = [dict_test_patients_masks_paths[patient] + file for file in list_files]\n",
    "    dict_test_patients_masks_paths[patient] = list_files\n",
    "    \n",
    "\n",
    "for patient in tqdm(dict_train_patients_scans_paths):\n",
    "    list_files = os.listdir(dict_train_patients_scans_paths[patient])\n",
    "    list_files = [dict_train_patients_scans_paths[patient] + file for file in list_files]\n",
    "    dict_train_patients_scans_paths[patient] = list_files\n",
    "    \n",
    "for patient in tqdm(dict_test_patients_scans_paths):\n",
    "    list_files = os.listdir(dict_test_patients_scans_paths[patient])\n",
    "    list_files = [dict_test_patients_scans_paths[patient] + file for file in list_files]\n",
    "    dict_test_patients_scans_paths[patient] = list_files\n",
    "    \n",
    "# Preprocessing:\n",
    "\n",
    "df_train = df_train.groupby(['Patient', 'Weeks']).agg({\n",
    "    'FVC': np.mean,\n",
    "    'Percent': np.mean,\n",
    "    'Age': np.max,\n",
    "    'Sex': np.max,\n",
    "    'SmokingStatus': np.max \n",
    "}).reset_index()\n",
    "\n",
    "df_train['FVC_Percent'] = (df_train['FVC'] / df_train['Percent']) * 100\n",
    "df_test['FVC_Percent'] = (df_test['FVC'] / df_test['Percent']) * 100\n",
    "\n",
    "\n",
    "# Standarize data\n",
    "\n",
    "mean_fvc, std_fvc = df_train.FVC.mean(), df_train.FVC.std()\n",
    "mean_perc, std_perc = df_train.Percent.mean(), df_train.Percent.std()\n",
    "mean_age, std_age = df_train.Age.mean(), df_train.Age.std()\n",
    "\n",
    "df_train['Age'] = df_train['Age'].apply(lambda x: (x-mean_age)/std_age)\n",
    "df_test['Age'] = df_test['Age'].apply(lambda x: (x-mean_age)/std_age)\n",
    "\n",
    "df_train['FVC'] = df_train['FVC'].apply(lambda x: (x-mean_fvc)/std_fvc)\n",
    "df_test['FVC'] = df_test['FVC'].apply(lambda x: (x-mean_fvc)/std_fvc)\n",
    "df_train['FVC_Percent'] = df_train['FVC_Percent'].apply(lambda x: (x-mean_fvc)/std_fvc)\n",
    "df_test['FVC_Percent'] = df_test['FVC_Percent'].apply(lambda x: (x-mean_fvc)/std_fvc)\n",
    "\n",
    "df_train['Percent'] = df_train['Percent'].apply(lambda x: (x-mean_perc)/std_perc)\n",
    "df_test['Percent'] = df_test['Percent'].apply(lambda x: (x-mean_perc)/std_perc)\n",
    "\n",
    "# Mapping categories dictionaries \n",
    "\n",
    "dict_sex = {'Male': 0, 'Female': 1}\n",
    "dict_sex_inv = {0: 'Male', 1: 'Female'}\n",
    "\n",
    "dict_smoke = {'Ex-smoker': 0, 'Never smoked': 1, 'Currently smokes': 2}\n",
    "dict_smoke_inv = {0: 'Ex-smoker', 1:'Never smoked', 2:'Currently smokes'}\n",
    "\n",
    "dict_kind_patient = {'decreased': 0, 'regular': 1, 'increased': 2}\n",
    "dict_kind_patient_inv = {0: 'decreased', 1: 'regular', 2: 'increased'}\n",
    "\n",
    "df_train.Sex = df_train.Sex.apply(lambda x: dict_sex[x])\n",
    "df_train.SmokingStatus = df_train.SmokingStatus.apply(lambda x: dict_smoke[x])\n",
    "\n",
    "df_test.Sex = df_test.Sex.apply(lambda x: dict_sex[x])\n",
    "df_test.SmokingStatus = df_test.SmokingStatus.apply(lambda x: dict_smoke[x])\n",
    "\n",
    "# Build WeeksSinceLastVisit feature\n",
    "\n",
    "df_train['ElapsedWeeks'] = df_train['Weeks']\n",
    "df_test['ElapsedWeeks'] = df_test['Weeks']\n",
    "\n",
    "train_weeks_elapsed = df_train.set_index(['Patient', 'Weeks'])['ElapsedWeeks'].diff().reset_index()\n",
    "test_weeks_elapsed = df_test.set_index(['Patient', 'Weeks'])['ElapsedWeeks'].diff().reset_index()\n",
    "\n",
    "df_train = df_train.drop('ElapsedWeeks', axis=1)\n",
    "df_test = df_test.drop('ElapsedWeeks', axis=1)\n",
    "\n",
    "train_weeks_elapsed['ElapsedWeeks'] = train_weeks_elapsed['ElapsedWeeks'].fillna(0).astype(int)\n",
    "test_weeks_elapsed['ElapsedWeeks'] = test_weeks_elapsed['ElapsedWeeks'].fillna(0).astype(int)\n",
    "\n",
    "df_train = df_train.merge(train_weeks_elapsed, how='inner', on=['Patient', 'Weeks'])\n",
    "df_test = df_test.merge(test_weeks_elapsed, how='inner', on=['Patient', 'Weeks'])\n",
    "\n",
    "df_train['patient_row'] = df_train.sort_values(['Patient', 'Weeks'], ascending=[True, True]) \\\n",
    "             .groupby(['Patient']) \\\n",
    "             .cumcount() + 1\n",
    "\n",
    "df_test['patient_row'] = df_test.sort_values(['Patient', 'Weeks'], ascending=[True, True]) \\\n",
    "             .groupby(['Patient']) \\\n",
    "             .cumcount() + 1\n",
    "\n",
    "df_train['WeeksSinceLastVisit'] = df_train.apply(lambda x: x['Weeks'] if x['patient_row']==1 else x['ElapsedWeeks'], axis=1)\n",
    "df_test['WeeksSinceLastVisit'] = df_test.apply(lambda x: x['Weeks'] if x['patient_row']==1 else x['ElapsedWeeks'], axis=1)\n",
    "\n",
    "# Norm Weeks\n",
    "\n",
    "mean_weeks, std_weeks = df_train.Weeks.mean(), df_train.Weeks.std()\n",
    "\n",
    "df_train['WeeksSinceLastVisit'] = df_train['WeeksSinceLastVisit'].apply(lambda x: (x-mean_weeks)/std_weeks)\n",
    "df_test['WeeksSinceLastVisit'] = df_test['WeeksSinceLastVisit'].apply(lambda x: (x-mean_weeks)/std_weeks)\n",
    "\n",
    "\n",
    "df_train['Weeks'] = df_train['Weeks'].apply(lambda x: (x-mean_weeks)/std_weeks)\n",
    "df_test['Weeks'] = df_test['Weeks'].apply(lambda x: (x-mean_weeks)/std_weeks)\n",
    "\n",
    "# Ini dictionaries\n",
    "\n",
    "columns = ['FVC', 'Age', 'Sex', 'SmokingStatus', 'WeeksSinceLastVisit', 'Percent']\n",
    "dict_patients_train_ini_features, dict_patients_test_ini_features = {}, {}\n",
    "dict_patients_train_kind_patient, dict_patients_test_kind_patient = {}, {}\n",
    "df_train_patients, df_test_patients = df_train.set_index('Patient'), df_test.set_index('Patient')\n",
    "\n",
    "for patient in unique_train_patients:\n",
    "    dict_patients_train_ini_features[patient] = df_train_patients[columns][df_train_patients.index==patient].\\\n",
    "                                                                    to_dict('records')[0]\n",
    "    std = np.std(unscale(df_train_patients['FVC'][df_train_patients.index==patient], mean_fvc, std_fvc).values)\n",
    "    mean_first_1 = np.mean(unscale(df_train_patients['FVC'][df_train_patients.index==patient], mean_fvc, std_fvc).values[:1])\n",
    "    mean_last_1 = np.mean(unscale(df_train_patients['FVC'][df_train_patients.index==patient], mean_fvc, std_fvc).values[-1:])\n",
    "    if std<=100:\n",
    "        dict_patients_train_kind_patient[patient] = 'regular'\n",
    "    elif std>100 and mean_last_1 > mean_first_1 :\n",
    "        dict_patients_train_kind_patient[patient] = 'increased'\n",
    "    elif std>100 and mean_last_1 <= mean_first_1 :\n",
    "        dict_patients_train_kind_patient[patient] = 'decreased'\n",
    "    dict_patients_train_ini_features[patient]['kind'] = dict_kind_patient[dict_patients_train_kind_patient[patient]]\n",
    "        \n",
    "    \n",
    "for patient in unique_test_patients:\n",
    "    dict_patients_test_ini_features[patient] = df_test_patients[columns][df_test_patients.index==patient].\\\n",
    "                                                                    to_dict('records')[0]\n",
    "    std = np.std(unscale(df_train_patients['FVC'][df_train_patients.index==patient], mean_fvc, std_fvc).values)\n",
    "    mean_first_1 = np.mean(unscale(df_train_patients['FVC'][df_train_patients.index==patient], mean_fvc, std_fvc).values[:1])\n",
    "    mean_last_1 = np.mean(unscale(df_train_patients['FVC'][df_train_patients.index==patient], mean_fvc, std_fvc).values[-1:])\n",
    "    if std<=100:\n",
    "        dict_patients_test_kind_patient[patient] = 'regular'\n",
    "    elif std>100 and mean_last_1 > mean_first_1 :\n",
    "        dict_patients_test_kind_patient[patient] = 'increased'\n",
    "    elif std>100 and mean_last_1 <= mean_first_1 :\n",
    "        dict_patients_test_kind_patient[patient] = 'decreased'\n",
    "    dict_patients_test_ini_features[patient]['kind'] = dict_kind_patient[dict_patients_test_kind_patient[patient]]\n",
    "\n",
    "# Decoder inputs\n",
    "\n",
    "dict_train_sequence_fvc, dict_train_sequence_weekssincelastvisit = {}, {}\n",
    "dict_train_sequence_cumweeks = {}\n",
    "for patient in unique_train_patients:\n",
    "    dict_train_sequence_fvc[patient] = list(df_train_patients['FVC'].loc[patient].values[1:])\n",
    "    dict_train_sequence_weekssincelastvisit[patient] = list(df_train_patients['WeeksSinceLastVisit'].loc[patient].values[1:])\n",
    "    dict_train_sequence_cumweeks[patient] = list(df_train_patients['Weeks'].loc[patient].values[1:])\n",
    "\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Generator\n",
    "\n",
    "Similar as `03_Autoencoder` Training Generator but instead of imgs as output we will have the ini features that we will use as our encoder input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "\n",
    "## 04. Data Generator\n",
    "\n",
    "class SequenceToSequenceDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, raw_scans, training, patients, dict_ini_features, dict_patients_masks_paths,\n",
    "                 batch_size=1, num_frames_batch=32, dict_raw_scans_paths=None, \n",
    "                 alpha=1.0, random_window=False, center_crop=True,\n",
    "                 img_size_load=(500, 500, 3), \n",
    "                 img_size_crop=(440, 440, 3)):\n",
    "        \n",
    "        super(SequenceToSequenceDataGenerator, self).__init__()\n",
    "        self.raw_scans = raw_scans\n",
    "        self.training = training\n",
    "        self.dict_ini_features = dict_ini_features\n",
    "        self.batch_size = batch_size\n",
    "        self.num_frames_batch = num_frames_batch\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.random_window = random_window\n",
    "        self.center_crop = center_crop\n",
    "        self.img_size_load = img_size_load\n",
    "        self.img_size_crop = img_size_crop\n",
    "        \n",
    "        self.dict_patients_masks_paths = dict_patients_masks_paths\n",
    "        self.dict_raw_scans_paths = dict_raw_scans_paths\n",
    "        \n",
    "        self.ids = patients\n",
    "#         self.pre_calculated_mean = 0.02865046213070556\n",
    "        self.num_steps = int(np.ceil(len(self.ids) / self.batch_size))\n",
    "        self.on_epoch_end()\n",
    "      \n",
    "    # Number of batches in the sequence\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_steps\n",
    "    \n",
    "    \n",
    "    # Gets the batch at position index, return patient images and dict ini features\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        patient_ids = [self.ids[k] for k in indexes]\n",
    "        if not self.raw_scans:\n",
    "            list_scan_imgs = [decodePatientImages(patient, \n",
    "                                                  self.dict_patients_masks_paths,\n",
    "                                                  image_size=(self.img_size_load[0], self.img_size_load[1]), \n",
    "                                                  numpy=True) \n",
    "                              for patient in patient_ids]\n",
    "        else:\n",
    "            list_scan_imgs = self.preprocessRawScans(patient_ids)\n",
    "           \n",
    "        patient_imgs = self.groupImages(list_scan_imgs)\n",
    "#         patient_imgs -= self.pre_calculated_mean\n",
    "#         print(patient_imgs.shape)\n",
    "#         patient_imgs = self.fullcenter3DCropping(patient_imgs)\n",
    "#         print(patient_imgs.shape) \n",
    "        patient_imgs = self.loadImagesAugmented(patient_imgs)\n",
    "        for patient_ in patient_ids:\n",
    "            self.dict_ini_features[patient_]['Patient'] = patient_\n",
    "        return (patient_imgs, [self.dict_ini_features[patient_] for patient_ in patient_ids])\n",
    "    \n",
    "    \n",
    "    # Preprocess Raw Scans in dicom format\n",
    "    \n",
    "    def preprocessRawScans(self, patient_ids):\n",
    "        patients_files = [self.dict_raw_scans_paths[patient] for patient in patient_ids]\n",
    "        patients_slices = [loadSlices(p) for p in patients_files]\n",
    "        patients_images = [getPixelsHu(p_slices) for p_slices in patients_slices]\n",
    "        patients_resampled_imgs = [resampleImages(p_images, p_slice, [1, 1, 1])[0] \\\n",
    "                                            for p_images, p_slice in zip(patients_images, patients_slices)]\n",
    "        patients_crop_imgs = [np.asarray([imCropCenter(img, 320, 320) for img in p_resampled_imgs]) \\\n",
    "                              for p_resampled_imgs in patients_resampled_imgs]\n",
    "        patients_segmented_lungs_fill = [np.asarray([seperateLungs(img, n_iters=2, only_internal=False, only_watershed=True)\n",
    "                                                    for img in p_crop_imgs]) for p_crop_imgs in patients_crop_imgs]\n",
    "        patients_masked_imgs = [np.where(p_lungs_fill==255, p_imgs, -2_048) \\\n",
    "                                for p_lungs_fill, p_imgs in zip(patients_segmented_lungs_fill, patients_crop_imgs)]\n",
    "        \n",
    "        patients_imgs = [windowImageNorm(p_imgs, min_bound=-1_000, max_bound=400) for p_imgs in patients_masked_imgs]\n",
    "        patients_imgs = [tf.convert_to_tensor(img, dtype=tf.float32) for img in patients_imgs]\n",
    "        patients_img_resized = [tf.convert_to_tensor([tf.image.resize(tf.expand_dims(img, axis=2), \n",
    "                                                                      (self.img_size_load[0], self.img_size_load[1])) \n",
    "                                                      for img in p_imgs], \n",
    "                                           dtype=tf.float32) for p_imgs in patients_imgs]\n",
    "        return patients_img_resized\n",
    "        \n",
    "    \n",
    "    # From n patient frames we will only keep self.alpha*n frames, cutting on top and bottom\n",
    "    \n",
    "    def filterSlices(self, array_imgs):\n",
    "        num_patient_slices = array_imgs.shape[0]\n",
    "        beta = int(self.alpha * num_patient_slices)\n",
    "        if beta % 2 != 0:\n",
    "            beta += 1\n",
    "        if num_patient_slices > self.num_frames_batch:\n",
    "            if beta > self.num_frames_batch and self.alpha < 1:\n",
    "                remove = int((num_patient_slices - beta)/2)\n",
    "                array_imgs = array_imgs[remove:, :, :, :]\n",
    "                array_imgs = array_imgs[:-remove:, :, :]\n",
    "\n",
    "        return array_imgs\n",
    "    \n",
    "    # Skip frames unniformally according to self.num_frames_batch value\n",
    "    \n",
    "    def frameSkipImages(self, patient_imgs):\n",
    "        num_patient_slices = patient_imgs.shape[0]\n",
    "        frame_skip = num_patient_slices // self.num_frames_batch\n",
    "        skipped_patient_imgs = np.zeros((self.num_frames_batch, self.img_size_load[0], self.img_size_load[1], 1))\n",
    "        for i in range(self.num_frames_batch):\n",
    "            skipped_patient_imgs[i] = patient_imgs[i*frame_skip]    \n",
    "        return skipped_patient_imgs\n",
    "    \n",
    "    # Select a random window of patient frames, in case its images has more frames than self.num_frame_batch \n",
    "    \n",
    "    def randomWindow(self, patient_imgs):\n",
    "        windowed_imgs = np.zeros((self.num_frames_batch, patient_imgs.shape[1], patient_imgs.shape[2], 1))\n",
    "        num_frames = patient_imgs.shape[0]\n",
    "        if num_frames < self.num_frames_batch:\n",
    "            windowed_imgs[:num_frames] = patient_imgs\n",
    "        else:\n",
    "            random_frames = np.arange(num_frames)\n",
    "            index = np.random.randint(0, num_frames - self.num_frames_batch)\n",
    "            windowed_imgs[0:] = patient_imgs[index:index+self.num_frames_batch]\n",
    "        return windowed_imgs\n",
    "            \n",
    "    \n",
    "    # Convert raw frames to a fix size array -> (batch_size, num_frames_batch, img_size_crop[0], img_size_crop[1], 1)\n",
    "    \n",
    "    def groupImages(self, list_scan_imgs):\n",
    "        grouped_imgs = []\n",
    "        for patient_imgs in list_scan_imgs:\n",
    "            if patient_imgs.shape[1] > self.num_frames_batch:\n",
    "                patient_imgs = self.filterSlices(patient_imgs)\n",
    "            if self.random_window:\n",
    "                patient_imgs = self.randomWindow(patient_imgs)\n",
    "            else:\n",
    "                patient_imgs = self.frameSkipImages(patient_imgs)\n",
    "            grouped_imgs.append(patient_imgs)\n",
    "        return np.asarray(grouped_imgs)\n",
    "        \n",
    "    # Performs augmentation operations conserving the 3D property on the z axis\n",
    "    \n",
    "    def loadImagesAugmented(self, patient_imgs):\n",
    "\n",
    "        if self.center_crop: #self.img_size_load != self.img_size_crop:\n",
    "            # patient_imgs = self.center3Dcropping(patient_imgs)\n",
    "            if patient_imgs.shape[2] > self.img_size_crop[0] and patient_imgs.shape[3] > self.img_size_crop[1]:\n",
    "                patient_imgs = self.random3DCropping(patient_imgs)\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = np.fliplr(patient_imgs)\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = np.flipud(patient_imgs)\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = patient_imgs[:, :, ::-1]\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = patient_imgs[:, ::-1, :]\n",
    "        if self.training:\n",
    "            patient_rotated_imgs= []\n",
    "            angle = np.random.randint(-15, 15)\n",
    "            for batch in range(patient_imgs.shape[0]):\n",
    "                batch_imgs_rotated = np.asarray([ndimage.rotate(patient_imgs[batch, i], angle, order=1,\n",
    "                                                                reshape=False) for i in range(patient_imgs.shape[1])])\n",
    "                patient_rotated_imgs.append(batch_imgs_rotated)\n",
    "            patient_imgs = np.asarray(patient_rotated_imgs) \n",
    "        return patient_imgs\n",
    "    \n",
    "    # gull Center 3d Cropping \n",
    "    \n",
    "    def fullcenter3DCropping(self, patient_imgs):\n",
    "        cropped_imgs = []\n",
    "        for batch in range(patient_imgs.shape[0]):\n",
    "            imgs = np.asarray([cropLung(patient_imgs[batch, img].squeeze()) for img in range(patient_imgs.shape[1])])\n",
    "            cropped_imgs.append(imgs)\n",
    "\n",
    "        return np.expand_dims(np.asarray(cropped_imgs), axis=-1)\n",
    "    \n",
    "    #Random Cropping 3D - change x, y axis but not z\n",
    "    \n",
    "    def random3DCropping(self, patient_imgs):\n",
    "        w, h = self.img_size_crop[0], self.img_size_crop[1]\n",
    "        x = np.random.randint(0, patient_imgs.shape[2] - w)\n",
    "        y = np.random.randint(0, patient_imgs.shape[2] - h)\n",
    "        patient_crop_imgs = patient_imgs[:, :, y:y+h, x:x+w]\n",
    "        return patient_crop_imgs\n",
    "    \n",
    "    # Center 3D Cropping\n",
    "    \n",
    "    def center3Dcropping(self, patient_imgs):\n",
    "        w, h = patient_imgs.shape[2] - 20, patient_imgs.shape[3] - 20\n",
    "        img_height, img_width = patient_imgs.shape[2], patient_imgs.shape[3]\n",
    "        left, right = (img_width - w) / 2, (img_width + w) / 2\n",
    "        top, bottom = (img_height - h) / 2, (img_height + h) / 2\n",
    "        left, top = round(max(0, left)), round(max(0, top))\n",
    "        right, bottom = round(min(img_width - 0, right)), round(min(img_height - 0, bottom))\n",
    "        patient_crop_imgs = patient_imgs[:, :, top:bottom, left:right]\n",
    "        return patient_crop_imgs\n",
    "    \n",
    "    # We shuffle the data at the end of each epoch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.ids))\n",
    "        np.random.shuffle(self.indexes)\n",
    "     \n",
    "    # Get only one patient, for debugging or prediction\n",
    "        \n",
    "    def getOnePatient(self, patient_id):\n",
    "        if not self.raw_scans:\n",
    "            list_scan_imgs = [decodePatientImages(patient_id, \n",
    "                                                  self.dict_patients_masks_paths,\n",
    "                                                  image_size=(self.img_size_load[0], self.img_size_load[1]), \n",
    "                                                  numpy=True)]\n",
    "        else:\n",
    "            list_scan_imgs = self.preprocessRawScans([patient_id])\n",
    "            \n",
    "        patient_imgs = self.groupImages(list_scan_imgs)\n",
    "        patient_imgs = self.loadImagesAugmented(patient_imgs)\n",
    "        self.dict_ini_features[patient_id]['Patient'] = patient_id\n",
    "        return (patient_imgs, [self.dict_ini_features[patient_id]])\n",
    "\n",
    "    \n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "\n",
    "## 05. Models\n",
    "\n",
    "### 05.1 Backbone 3D Image Model\n",
    "\n",
    "class BackBone3DModel(models.Model):\n",
    "    \n",
    "    def __init__(self, unet=False, path_unet=None, resnet=False, path_resnet=None, features_dim=256):\n",
    "        super(BackBone3DModel, self).__init__(name='BackBone3DModel')\n",
    "        self.unet = unet\n",
    "        self.path_unet = path_unet\n",
    "        self.resnet = resnet\n",
    "        self.path_resnet = path_resnet\n",
    "        if self.unet:\n",
    "            self.unet_model = tf.keras.models.load_model(self.path_unet, compile=False) \n",
    "            self.unet_model.trainable = False\n",
    "        if self.resnet:\n",
    "            self.resnet_model = tf.keras.models.load_model(self.path_resnet, compile=False) \n",
    "            self.resnet_model.trainable = True \n",
    "        else:\n",
    "            self.avg_pool = layers.AvgPool3D(pool_size=(2, 1, 1), name='avg_pool')\n",
    "            \n",
    "            self.input_batch_norm = layers.BatchNormalization()\n",
    "            \n",
    "            self.block1_conv1 = layers.Conv3D(32, kernel_size=(1, 3, 3), padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block1_conv1',\n",
    "                                              data_format='channels_last')\n",
    "            self.block1_conv2 = layers.Conv3D(32, kernel_size=(1, 3, 3), padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block1_conv2',\n",
    "                                              data_format='channels_last')\n",
    "            self.block1_maxpool1 = layers.MaxPool3D(pool_size=(2, 2, 2), name='block1_maxpool1',\n",
    "                                              data_format='channels_last')\n",
    "            self.block_1_dropout = layers.Dropout(0.2)\n",
    "\n",
    "            self.block2_conv1 = layers.Conv3D(64, kernel_size=(1, 3, 3), padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block2_conv1',\n",
    "                                              data_format='channels_last')\n",
    "            self.block2_conv2 = layers.Conv3D(64, kernel_size=(1, 3, 3),padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block2_conv2',\n",
    "                                              data_format='channels_last')\n",
    "            self.block2_maxpool1 = layers.MaxPool3D(pool_size=(2, 2, 2), name='block2_maxpool1',\n",
    "                                              data_format='channels_last')\n",
    "            self.block_2_dropout = layers.Dropout(0.3)\n",
    "\n",
    "            self.block3_conv1 = layers.Conv3D(128, kernel_size=(1, 3, 3), padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block3_conv1',\n",
    "                                              data_format='channels_last')\n",
    "            self.block3_conv2 = layers.Conv3D(128, kernel_size=(1, 3, 3), padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block3_conv2',\n",
    "                                              data_format='channels_last')\n",
    "            \n",
    "            self.block_3_dropout = layers.Dropout(0.4)\n",
    "            \n",
    "            self.block3_maxpool1 = layers.MaxPool3D(pool_size=(2, 2, 2), name='block2_maxpool1',\n",
    "                                              data_format='channels_last')\n",
    "\n",
    "            self.block4_conv1 = layers.Conv3D(256, kernel_size=(1, 3, 3), padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block3_conv1',\n",
    "                                              data_format='channels_last')\n",
    "            self.block4_conv2 = layers.Conv3D(256, kernel_size=(1, 3, 3), padding='same', \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              kernel_initializer = initializers.RandomNormal(stddev=0.01),\n",
    "                                              activation='relu', name='block3_conv2',\n",
    "                                              data_format='channels_last')\n",
    "            \n",
    "            self.glob_max_pool = layers.GlobalMaxPooling3D()\n",
    "\n",
    "        \n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        if self.unet:\n",
    "            x = self.unet_model(inputs, training)\n",
    "            # (None, 2, 20, 20, 256)\n",
    "        elif self.resnet:\n",
    "            x = self.resnet_model(inputs, training)\n",
    "        else:\n",
    "            x = self.avg_pool(inputs)\n",
    "#             x = self.input_batch_norm(x, training)\n",
    "            \n",
    "            x = self.block1_conv1(x)\n",
    "            x = self.block1_conv2(x)\n",
    "            x = self.block1_maxpool1(x)\n",
    "            x = self.block_1_dropout(x, training)\n",
    "\n",
    "            x = self.block2_conv1(x)\n",
    "            x = self.block2_conv2(x)\n",
    "            x = self.block2_maxpool1(x)\n",
    "            x = self.block_2_dropout(x, training)\n",
    "\n",
    "            x = self.block3_conv1(x)\n",
    "            x = self.block3_conv2(x)\n",
    "            x = self.block3_maxpool1(x)\n",
    "            x = self.block_3_dropout(x, training)\n",
    "            \n",
    "            x = self.block4_conv1(x)\n",
    "            x = self.block4_conv2(x)\n",
    "            \n",
    "            x = self.glob_max_pool(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "\n",
    "### 05.2 Backbone Tabular Data for Patients metadata\n",
    "\n",
    "class BackBoneTabularModel(models.Model):\n",
    "    \n",
    "    def __init__(self, dense_dim, dropout_rate, sex_dim=20, smoker_dim=20, max_norm=1):\n",
    "        super(BackBoneTabularModel, self).__init__(name='BackBoneTabularModel')\n",
    "        \n",
    "        self.dense_dim = dense_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    " \n",
    "        self.sex_dim = sex_dim \n",
    "        self.smoker_dim = smoker_dim\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.emb_sex = layers.Embedding(input_dim=2, output_dim=self.sex_dim, \n",
    "                                       embeddings_regularizer=regularizers.l2(1e-4))\n",
    "                                       #embeddings_constraint=constraints.MaxNorm(max_norm))\n",
    "                                    \n",
    "        self.emb_smoker = layers.Embedding(input_dim=3, output_dim=self.smoker_dim,\n",
    "                                           embeddings_regularizer=regularizers.l2(1e-4))\n",
    "                                           #embeddings_constraint=constraints.MaxNorm(max_norm))\n",
    "        \n",
    "        self.emb_kind = layers.Embedding(input_dim=3, output_dim=self.smoker_dim,\n",
    "                                         embeddings_regularizer=regularizers.l2(1e-4))\n",
    "                                         #embeddings_constraint=constraints.MaxNorm(max_norm))\n",
    "        \n",
    "        # Output layer\n",
    "        self.dropout_1 = layers.Dropout(self.dropout_rate)\n",
    "        self.dense_1 = layers.Dense(units=self.dense_dim,\n",
    "                                  activation=None,\n",
    "                                  kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                  bias_regularizer=regularizers.l2(1e-4),\n",
    "                                  activity_regularizer=regularizers.l2(1e-4),\n",
    "                                  kernel_constraint = constraints.MaxNorm(max_norm),\n",
    "                                  bias_constraint=constraints.MaxNorm(max_norm),\n",
    "                                  name='tabular_dense1')\n",
    "        self.batch_norm_1 = layers.BatchNormalization(axis=-1)\n",
    "        \n",
    "        self.dropout_2 = layers.Dropout(0.2)\n",
    "        \n",
    "        self.dense_2 = layers.Dense(units=self.dense_dim//2,\n",
    "                                  activation=None,\n",
    "                                  kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                  bias_regularizer=regularizers.l2(1e-4),\n",
    "                                  activity_regularizer=regularizers.l2(1e-4),\n",
    "                                  kernel_constraint = constraints.MaxNorm(max_norm),\n",
    "                                  bias_constraint=constraints.MaxNorm(max_norm),\n",
    "                                  name='tabular_dense2')\n",
    "        self.batch_norm_2 = layers.BatchNormalization(axis=-1)\n",
    "        \n",
    "    def call(self, inputs, training=True):\n",
    "\n",
    "        patient_sex = self.emb_sex(inputs[:, 0])\n",
    "        patient_smoke = self.emb_smoker(inputs[:, 1])\n",
    "        # patient_kind = self.emb_kind(inputs[:, 2])\n",
    "        \n",
    "        x = tf.concat([patient_sex,\n",
    "                       patient_smoke,\n",
    "                       # patient_kind,\n",
    "                       tf.expand_dims(inputs[:, 2], 1), #Age\n",
    "                       tf.expand_dims(inputs[:, 3], 1), # Percent\n",
    "                       tf.expand_dims(inputs[:, 4], 1), # WeeksSinceLastVisit\n",
    "                       tf.expand_dims(inputs[:, 5], 1)], # Ini FVC\n",
    "                axis=-1) \n",
    "        \n",
    "        x = self.dropout_1(x, training)\n",
    "        x = self.dense_1(x)\n",
    "#         x = self.batch_norm_1(x, training)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "#         x = self.dropout_2(x, training)\n",
    "#         x = self.dense_2(x)\n",
    "#         x = self.batch_norm_2(x, training)\n",
    "#         x = tf.nn.relu(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "                      \n",
    "### 05.3 Encoder Model\n",
    "\n",
    "class Encoder(models.Model):\n",
    "    \n",
    "    def __init__(self, features_dim, dropout_rate=[0.2], \n",
    "                       unet=False, path_unet=None,\n",
    "                       resnet=False, path_resnet=None,\n",
    "                       tabular_dense_dim=16, tabular_dropout_rate=0.4,\n",
    "                       tabular_sex_dim=10, tabular_smoker_dim=10, max_norm=1, recurrent_max_norm=0.1,\n",
    "                       attention_max_norm=0.1,\n",
    "                     **kwargs):\n",
    "                    \n",
    "        super(Encoder, self).__init__( **kwargs, name='Encoder')\n",
    "        self.features_dim = features_dim\n",
    "        self.backbone_img_model = BackBone3DModel(unet, path_unet, resnet, path_resnet, features_dim)\n",
    "        self.backbone_tabular_model = BackBoneTabularModel(dense_dim=tabular_dense_dim, \n",
    "                                                           dropout_rate=tabular_dropout_rate,  \n",
    "                                                           sex_dim=tabular_sex_dim, \n",
    "                                                           smoker_dim=tabular_smoker_dim,\n",
    "                                                           max_norm=max_norm)\n",
    "               \n",
    "        # Conv1d - Block \n",
    "        self.dropout_conv_1 = layers.Dropout(dropout_rate[0])\n",
    "        self.dropout_conv_2 = layers.Dropout(dropout_rate[0])\n",
    "        self.conv1d_1 = layers.Conv1D(filters=features_dim, kernel_size=3, activation='relu', \n",
    "                                      dilation_rate=1, padding='same', data_format='channels_last',\n",
    "                                      kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                      kernel_constraint=constraints.MaxNorm(max_norm))\n",
    "        self.batch_norm_conv1d_1 = layers.BatchNormalization()\n",
    "        self.conv1d_2 = layers.Conv1D(filters=features_dim, kernel_size=3, activation='relu',\n",
    "                                      dilation_rate=1,  padding='same', data_format='channels_last',\n",
    "                                      kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                      kernel_constraint=constraints.MaxNorm(max_norm))\n",
    "        self.batch_norm_conv1d_2 = layers.BatchNormalization()\n",
    "        self.max_pool_1d_1 = layers.MaxPool1D(pool_size=(2), data_format='channels_last')\n",
    "        self.max_pool_1d_2 = layers.MaxPool1D(pool_size=(2), data_format='channels_last')\n",
    "        \n",
    "        # Gru Block\n",
    "        \n",
    "        self.gru_encoder_2 = layers.GRU(self.features_dim, \n",
    "                                      dropout=dropout_rate[-1],\n",
    "                                      return_sequences=True, \n",
    "                                      return_state=True,\n",
    "                                      bias_constraint=constraints.MaxNorm(max_norm),\n",
    "                                      kernel_constraint=constraints.MaxNorm(max_norm),\n",
    "                                      recurrent_constraint=constraints.MaxNorm(recurrent_max_norm),\n",
    "                                      kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                      bias_regularizer=regularizers.l2(1e-4),\n",
    "                                        activity_regularizer=regularizers.l2(1e-4),\n",
    "                                      recurrent_initializer='glorot_uniform')\n",
    "                \n",
    "        # Output Block\n",
    "        self.dropout = layers.Dropout(0.3, name='dropout')\n",
    "        self.dense = layers.Dense(32, activation=None, name='encoder_dense',\n",
    "                                  kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                  bias_regularizer=regularizers.l2(1e-4),\n",
    "                                  kernel_constraint=constraints.MaxNorm(max_norm),\n",
    "                                  bias_constraint=constraints.MaxNorm(max_norm))\n",
    "        self.bn = layers.BatchNormalization(axis=-1)\n",
    "        \n",
    "    \n",
    "    def call(self, img_inputs, scalar_inputs, training=True):\n",
    "        \n",
    "        # Image Features from 3D Model\n",
    "        img_features = self.backbone_img_model(img_inputs, training)\n",
    "        img_features_origi = img_features\n",
    "#         img_dim = img_features.shape[1]*img_features.shape[2]*img_features.shape[3]\n",
    "#         img_features = tf.reshape(img_features, tf.convert_to_tensor([img_features.shape[0], \n",
    "#                                                                      img_dim, \n",
    "#                                                                      img_features.shape[4]]))\n",
    "        \n",
    "        img_features = tf.expand_dims(img_features, axis=1)\n",
    "\n",
    "#         img_features = self.dropout_conv_1(img_features, training)\n",
    "#         img_features = self.conv1d_1(img_features)\n",
    "#         img_features = self.conv1d_2(img_features)\n",
    "#         img_features = self.max_pool_1d_1(img_features)\n",
    "\n",
    "        \n",
    "        # Scalar Features from Patient Metadata\n",
    "        scalar_features_origi = self.backbone_tabular_model(scalar_inputs, training)\n",
    "        self.repeatvector = layers.RepeatVector(img_features.shape[1])\n",
    "        scalar_features = self.repeatvector(scalar_features_origi)\n",
    "        \n",
    "        \n",
    "        # Mixing both together\n",
    "        features_mixed = tf.concat(values=[img_features, scalar_features], axis=-1)\n",
    "\n",
    "        features, state = self.gru_encoder_2(features_mixed, \n",
    "                                             training=training)\n",
    "        \n",
    "        dec_enc_input = tf.concat([scalar_features_origi, scalar_inputs], axis=-1)\n",
    "\n",
    "        return (features, dec_enc_input), state\n",
    "\n",
    "\n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.features_dim))\n",
    "\n",
    "\n",
    "### 05.4 Decoder Model\n",
    "\n",
    "class Decoder(models.Model):\n",
    "    \n",
    "    def __init__(self, embedding_dim, rnn_units=[64], dense_units=[64], dense_activation='relu',\n",
    "                 dropout_rate=[0.2, 0.2], max_norm=1, recurrent_max_norm=1,\n",
    "                 attention_max_norm=1, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs, name='Decoder')\n",
    "        self.rnn_units = rnn_units\n",
    "        self.dense_units = dense_units\n",
    "        self.attention_features_shape = self.rnn_units[-1]\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.max_norm = max_norm\n",
    "        self.recurrent_max_norm = recurrent_max_norm\n",
    "        self.attention_layer = BahdanauAttention(self.attention_features_shape, attention_max_norm)   \n",
    "            \n",
    "        self.flatten = layers.Flatten(name='flatten')\n",
    "        self.dropout_1 = layers.Dropout(self.dropout_rate[0])\n",
    "        self.dropout_2 = layers.Dropout(self.dropout_rate[-1])\n",
    "        self.dense_activation = dense_activation\n",
    "        self.grus = self.stackRNN()\n",
    "        if self.dense_units:\n",
    "            self.fcc_denses = self.stackDense()\n",
    "            \n",
    "        self.dense_scalar = layers.Dense(units=64,\n",
    "                                  activation='relu',\n",
    "                                  kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                  bias_regularizer=regularizers.l2(1e-4),\n",
    "                                  activity_regularizer=regularizers.l2(1e-4),\n",
    "                                  kernel_constraint = constraints.MaxNorm(max_norm),\n",
    "                                  bias_constraint=constraints.MaxNorm(max_norm),\n",
    "                                  name='dense_scalar')\n",
    "        \n",
    "        self.drop_scalar = layers.Dropout(0.3)\n",
    "        \n",
    "        self.dense_output = layers.Dense(3, \n",
    "                                         kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                         bias_regularizer=regularizers.l2(1e-4),\n",
    "                                         activation='linear', name='output1')\n",
    "        self.dense_output_relu = layers.Dense(3, \n",
    "                                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                                              bias_regularizer=regularizers.l2(1e-4),\n",
    "                                              activation='relu', name='output2')\n",
    "        \n",
    "#         self.dense_output_softmax = layers.Dense(3, activation='softmax', name='output3')\n",
    "        self.quantiles_output = layers.Lambda(lambda x: x[0] + (tf.cumsum(x[1])), name='quantile_preds')\n",
    "        \n",
    "    \n",
    "    def call(self, decoder_input, features, initial_state, hidden, training=True):\n",
    "        img_features, scalar_features = features\n",
    "        \n",
    "        context_vector, attention_weights = self.attention_layer(img_features, hidden)\n",
    "        \n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1),\n",
    "                       tf.expand_dims(scalar_features, 1),\n",
    "                       tf.expand_dims(decoder_input, 1)], axis=-1)\n",
    "\n",
    "                    \n",
    "        for gru in self.grus[:-1]:\n",
    "            x = gru(x, training=training, initial_state=initial_state)\n",
    "        if len(self.grus) > 1:\n",
    "            x, state = self.grus[-1](x, training=training)\n",
    "        else:\n",
    "            x, state = self.grus[-1](x, training=training, initial_state=initial_state)\n",
    "            \n",
    "        if self.dense_units:\n",
    "            x = self.flatten(x)\n",
    "            x = self.dropout_1(x, training)\n",
    "            for fcc in self.fcc_denses:\n",
    "                x = fcc(x)\n",
    "                x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout_2(x, training=training)\n",
    "        ####\n",
    "        x_output_1 = self.dense_output(x)\n",
    "#         x_output_2 = self.dense_output_relu(x)\n",
    "#         x_output_3 = self.dense_output_softmax(x)\n",
    "        ###\n",
    "#         x_quantiles = self.quantiles_output([x_output_1, x_output_2])\n",
    "        \n",
    "        return x_output_1, state, attention_weights\n",
    "    \n",
    "    \n",
    "    def stackRNN(self):\n",
    "        rnns = []\n",
    "        for units in self.rnn_units[:-1]:\n",
    "            gru_ = layers.GRU(units,\n",
    "                              dropout=self.dropout_rate[0],\n",
    "                              return_state=False,\n",
    "                              return_sequences=True,\n",
    "                              bias_constraint=constraints.MaxNorm(self.max_norm),\n",
    "                              kernel_constraint=constraints.MaxNorm(self.max_norm),\n",
    "                              recurrent_constraint=constraints.MaxNorm(self.recurrent_max_norm),\n",
    "                              kernel_regularizer=regularizers.l2(1e-4),\n",
    "                              bias_regularizer=regularizers.l2(1e-4),\n",
    "                              activity_regularizer=regularizers.l2(1e-4),\n",
    "                              recurrent_initializer='glorot_uniform')\n",
    "            rnns.append(gru_)\n",
    "        \n",
    "        gru_ = layers.GRU(self.rnn_units[-1],\n",
    "                          dropout=self.dropout_rate[0],\n",
    "                          return_sequences=True, \n",
    "                          return_state=True,\n",
    "                          bias_constraint=constraints.MaxNorm(self.max_norm),\n",
    "                          kernel_constraint=constraints.MaxNorm(self.max_norm),\n",
    "                          recurrent_constraint=constraints.MaxNorm(self.recurrent_max_norm),\n",
    "                          kernel_regularizer=regularizers.l2(1e-4),\n",
    "                          bias_regularizer=regularizers.l2(1e-4),\n",
    "                          activity_regularizer=regularizers.l2(1e-4),\n",
    "                          recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "        rnns.append(gru_)\n",
    "        return rnns\n",
    "    \n",
    "    \n",
    "    def stackDense(self):\n",
    "        denses = []\n",
    "        for units in self.dense_units:\n",
    "            dense_ = layers.Dense(units,\n",
    "                               activation=None, #self.dense_activation\n",
    "                               bias_constraint=constraints.MaxNorm(self.max_norm),\n",
    "                               kernel_constraint=constraints.MaxNorm(self.max_norm),\n",
    "                               kernel_regularizer=regularizers.l2(1e-4), \n",
    "                               bias_regularizer=regularizers.l2(1e-4))\n",
    "            denses.append(dense_)\n",
    "        return denses\n",
    "    \n",
    "    \n",
    "    def reset_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.rnn_units[0]))\n",
    "\n",
    "\n",
    "### 05.5 Global Model\n",
    "    \n",
    "class PulmonarFibrosisEncoderDecoder(models.Model):\n",
    "    \n",
    "    def __init__(self, encoder_tabular_dense_dim, encoder_tabular_dropout_rate, \n",
    "                 encoder_tabular_sex_dim, encoder_tabular_smoker_dim, encoder_feature_dim, \n",
    "                 encoder_unet, encoder_path_unet, encoder_resnet, encoder_path_resnet,\n",
    "                 encoder_recurrent_max_norm, encoder_max_norm,\n",
    "                 encoder_dropout_rate, \n",
    "                 decoder_embedding_dim, decoder_rnn_units, \n",
    "                 decoder_dense_units, decoder_dense_activation,\n",
    "                 decoder_dropout_rate, decoder_max_norm, decoder_recurrent_max_norm,\n",
    "                 decoder_attention_max_norm, learning_rate, clipvalue,\n",
    "                 checkpoint_path, teacher_forcing, batch_size, quantiles, beta_factor, lambda_factor,\n",
    "                 first_epoch_learning_rate_epoch_decay, constant_learning_rate_epoch_decay,\n",
    "                 epsilon, epsilon_decay, save_checkpoints, \n",
    "                 restore_last_checkpoint, dict_train_sequence_fvc, dict_train_sequence_weekssincelastvisit,\n",
    "                 dict_train_sequence_cumweeks, dict_train_patients_masks_paths, \n",
    "                 dict_patients_train_ini_features, mean_fvc, std_fvc, num_fold,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(PulmonarFibrosisEncoderDecoder, self).__init__(**kwargs, name='PulmonarFibrosisEncoderDecoder')\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        # Global dicts\n",
    "        self.dict_train_sequence_fvc = dict_train_sequence_fvc\n",
    "        self.dict_train_sequence_weekssincelastvisit = dict_train_sequence_weekssincelastvisit\n",
    "        self.dict_train_sequence_cumweeks = dict_train_sequence_cumweeks\n",
    "        self.dict_train_patients_masks_paths = dict_train_patients_masks_paths\n",
    "        self.dict_patients_train_ini_features = dict_patients_train_ini_features\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_tabular_dense_dim = encoder_tabular_dense_dim\n",
    "        self.encoder_tabular_sex_dim = encoder_tabular_sex_dim\n",
    "        self.encoder_tabular_smoker_dim = encoder_tabular_smoker_dim\n",
    "        self.encoder_tabular_dropout_rate = encoder_tabular_dropout_rate\n",
    "        self.encoder_feature_dim = encoder_feature_dim\n",
    "        self.unet = encoder_unet\n",
    "        self.encoder_path_unet = encoder_path_unet\n",
    "        self.encoder_resnet = encoder_resnet\n",
    "        self.encoder_path_resnet = encoder_path_resnet\n",
    "        self.encoder_dropout_rate = encoder_dropout_rate\n",
    "        self.encoder_recurrent_max_norm = encoder_recurrent_max_norm\n",
    "        self.encoder_max_norm = encoder_max_norm\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_embedding_dim = decoder_embedding_dim\n",
    "        self.decoder_rnn_units = decoder_rnn_units\n",
    "        self.decoder_dense_units = decoder_dense_units\n",
    "        self.decoder_dropout_rate = decoder_dropout_rate\n",
    "        self.decoder_dense_activation = decoder_dense_activation\n",
    "        self.decoder_max_norm = decoder_max_norm\n",
    "        self.decoder_recurrent_max_norm = decoder_recurrent_max_norm\n",
    "        self.decoder_attention_max_norm = decoder_attention_max_norm\n",
    "        self.mean_fvc=mean_fvc\n",
    "        self.std_fvc=std_fvc\n",
    "        \n",
    "        # Utils - Training \n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.clipvalue = clipvalue\n",
    "        self.teacher_forcing = teacher_forcing\n",
    "        self.epsilon = tf.convert_to_tensor(epsilon, dtype=tf.float32)\n",
    "        self.epsilon_decay = tf.convert_to_tensor(epsilon_decay, dtype=tf.float32)\n",
    "        self.quantiles = tf.convert_to_tensor(quantiles)\n",
    "        self.beta_factor = tf.constant(beta_factor)\n",
    "        self.lambda_factor = tf.constant(lambda_factor)\n",
    "\n",
    "        # Build model\n",
    "        self.first_epoch_learning_rate_epoch_decay = first_epoch_learning_rate_epoch_decay\n",
    "        self.constant_learning_rate_epoch_decay = constant_learning_rate_epoch_decay\n",
    "        self.build()\n",
    "        self.compile()\n",
    "        \n",
    "        # Utils\n",
    "        self.save_checkpoints = save_checkpoints\n",
    "        self.checkpoint_path = checkpoint_path + f'{num_fold}/'\n",
    "        if self.save_checkpoints or restore_last_checkpoint:\n",
    "            self.buildCheckpoints()\n",
    "        if restore_last_checkpoint:\n",
    "            self.ckpt.restore(sorted(self.ckpt_manager.checkpoints)[-1])\n",
    "\n",
    "                \n",
    "                \n",
    "    def build(self):\n",
    "        self.encoder = Encoder(features_dim=self.encoder_feature_dim,\n",
    "                               tabular_sex_dim=self.encoder_tabular_sex_dim, \n",
    "                               tabular_smoker_dim=self.encoder_tabular_smoker_dim,\n",
    "                               tabular_dense_dim=self.encoder_tabular_dense_dim, \n",
    "                               tabular_dropout_rate=self.encoder_tabular_dropout_rate,\n",
    "                               dropout_rate=self.encoder_dropout_rate, \n",
    "                               unet=self.unet, path_unet=self.encoder_path_unet,\n",
    "                               resnet=self.encoder_resnet, path_resnet=self.encoder_path_resnet,\n",
    "                               recurrent_max_norm=self.encoder_recurrent_max_norm,\n",
    "                               max_norm=self.encoder_max_norm)\n",
    "        \n",
    "        self.decoder = Decoder(embedding_dim=self.decoder_embedding_dim, \n",
    "                               rnn_units=self.decoder_rnn_units, \n",
    "                               dense_units=self.decoder_dense_units, dropout_rate=self.decoder_dropout_rate,\n",
    "                               dense_activation=self.decoder_dense_activation,\n",
    "                               attention_max_norm=self.decoder_attention_max_norm, \n",
    "                               max_norm=self.decoder_max_norm,\n",
    "                               recurrent_max_norm=self.decoder_recurrent_max_norm)\n",
    "        \n",
    "        \n",
    "    def compile(self):\n",
    "        super(PulmonarFibrosisEncoderDecoder, self).compile()\n",
    "        \n",
    "        self.optimizer = optimizers.Adam(learning_rate=self.learning_rate, \n",
    "                                         clipvalue=self.clipvalue)\n",
    "#         self.optimizer = optimizers.SGD(self.learning_rate, \n",
    "#                                         momentum=0.9)\n",
    "        \n",
    "        self.loss_function = quantileLoss\n",
    "        self.custom_metric = customLossFunction\n",
    "        self.metric = [tf.keras.losses.MeanSquaredError(name='mse')]\n",
    "        \n",
    "       \n",
    "   \n",
    "    def buildCheckpoints(self):\n",
    "        if not os.path.exists(self.checkpoint_path):\n",
    "            os.mkdir(self.checkpoint_path)\n",
    "            \n",
    "        self.ckpt = tf.train.Checkpoint(encoder=self.encoder,\n",
    "                                        decoder=self.decoder,\n",
    "                                        optimizer=self.optimizer)\n",
    "\n",
    "        self.ckpt_manager = tf.train.CheckpointManager(self.ckpt, self.checkpoint_path, max_to_keep=10)\n",
    "        \n",
    "        \n",
    "    def learningRateDecay(self, epoch):\n",
    "        if epoch == 0:\n",
    "            self.optimizer.learning_rate = self.optimizer.learning_rate * self.first_epoch_learning_rate_epoch_decay\n",
    "        else:\n",
    "            self.optimizer.learning_rate = self.optimizer.learning_rate * self.constant_learning_rate_epoch_decay\n",
    "        \n",
    "        \n",
    "    @tf.function\n",
    "    def trainStep(self, img_tensor, features_tensor, weeks_since_lastvisit_tensor, weeks_since_firstvisit_tensor, \n",
    "                  initial_fvc, initial_weeks_since_lastvisit_tensor, initial_weeks_since_firstvisit_tensor,\n",
    "                  target):\n",
    "        loss, q_loss, metric1, metric2 = 0, 0, 0, 0\n",
    "        list_predictions, list_stds = [], []\n",
    "        decoder_input = tf.convert_to_tensor([[initial_fvc[0, 0], \n",
    "                                               initial_fvc[0, 0],\n",
    "                                               initial_fvc[0, 0],\n",
    "                                               initial_weeks_since_lastvisit_tensor,\n",
    "                                               initial_weeks_since_firstvisit_tensor]], dtype=np.float32)\n",
    "        \n",
    "        if self.beta_factor is not None:\n",
    "            last_3_weight = self.beta_factor\n",
    "            curr_weights = (1-self.beta_factor)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            features, encoder_state = self.encoder(img_tensor, \n",
    "                                                    features_tensor,\n",
    "                                                    training=True)\n",
    "            hidden = encoder_state\n",
    "            norm_weight = curr_weights / (target.shape[1] - 3)\n",
    "            l3_weight = last_3_weight / 3\n",
    "            \n",
    "            for i in range(0, weeks_since_lastvisit_tensor.shape[0]):\n",
    "                pred_output, hidden, attention_weights = self.decoder(decoder_input, \n",
    "                                                                      features, \n",
    "                                                                      initial_state=encoder_state,\n",
    "                                                                      hidden=hidden,\n",
    "                                                                      training=True)\n",
    " \n",
    "                pred_std = unscale(pred_output[:, 2], self.mean_fvc, self.std_fvc) - unscale(pred_output[:, 0], self.mean_fvc, self.std_fvc)\n",
    "                pred_mean = pred_output[:, 1]\n",
    "\n",
    "                loss_1 = self.loss_function(self.quantiles, \n",
    "                                          unscale(target[:, i], self.mean_fvc, self.std_fvc),\n",
    "                                          unscale(pred_output, self.mean_fvc, self.std_fvc))\n",
    "                \n",
    "    \n",
    "                loss_2 = self.custom_metric(unscale(target[:, i], self.mean_fvc, self.std_fvc),\n",
    "                                           unscale(pred_mean, self.mean_fvc, self.std_fvc), \n",
    "                                           std=pred_std)\n",
    "        \n",
    "                metric2 += self.metric[0](target[:, i], pred_mean)\n",
    "                \n",
    "                q_loss += loss_1\n",
    "                metric1 += loss_2\n",
    "                \n",
    "                if self.beta_factor>0:\n",
    "                    if i < (target.shape[1]-3):\n",
    "                        weight = norm_weight\n",
    "                    else:\n",
    "                        weight = l3_weight\n",
    "                    loss += ((loss_1 * self.lambda_factor) + (loss_2 * (1-self.lambda_factor)))*weight\n",
    "                else:\n",
    "                    loss += ((loss_1 * self.lambda_factor) + (loss_2 * (1-self.lambda_factor)))/target.shape[1]\n",
    "            \n",
    "                \n",
    "                # Teacher forcing\n",
    "                if self.teacher_forcing=='avg':\n",
    "                    teacher_forc = tf.expand_dims(tf.reduce_mean([target[:, i], pred_mean]), 0)\n",
    "                elif self.teacher_forcing=='random':\n",
    "                    random_ = np.random.random()\n",
    "                    if random_ > 0.5:\n",
    "                        teacher_forc = target[:, i]\n",
    "                        pred_output[:, 0] = scale(70, self.mean_fvc, self.std_fvc)\n",
    "                        pred_output[:, 2] = scale(70, self.mean_fvc, self.std_fvc)\n",
    "                    else:\n",
    "                        teacher_forc = pred_mean # pred_output[0]\n",
    "                else:\n",
    "                    teacher_forc = (target[:, i] * self.epsilon) + (pred_mean * (1-self.epsilon))\n",
    "                    \n",
    "                list_predictions.append(pred_mean)\n",
    "                list_stds.append(pred_std)\n",
    "                       \n",
    "                if i <= weeks_since_lastvisit_tensor.shape[0]:\n",
    "                    decoder_input = tf.expand_dims(tf.concat([pred_output[:, 0],\n",
    "                                                              teacher_forc,\n",
    "                                                              pred_output[:, 2],\n",
    "                                                              weeks_since_lastvisit_tensor[i],\n",
    "                                                              weeks_since_firstvisit_tensor[i]], axis=-1), 0)    \n",
    "                    \n",
    "        list_predictions = tf.convert_to_tensor(list_predictions)\n",
    "      \n",
    "        total_metric1 = metric1/int(target.shape[1])\n",
    "        total_metric2 = metric2/int(target.shape[1])\n",
    "        total_metric3 = self.custom_metric(unscale(target[:, -3:], self.mean_fvc, self.std_fvc),\n",
    "                                           unscale(list_predictions[-3:], self.mean_fvc, self.std_fvc), \n",
    "                                           std=list_stds[-3:])\n",
    "        \n",
    "        total_metrics = [total_metric1, total_metric2, total_metric3]\n",
    "        \n",
    "        trainable_variables = self.encoder.trainable_variables + self.decoder.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "        \n",
    "        return loss, list_predictions, total_metrics\n",
    "    \n",
    "    \n",
    "    def fitModel(self, X_train, X_val=None, epochs=1):\n",
    "        history = {}\n",
    "        history['loss'], history['val_loss'], history['metric'], history['val_metric'] = [], [], [], []\n",
    "        history['val_Metrict3Timesteps'] = []\n",
    "    \n",
    "        for epoch in range(0, epochs):\n",
    "            start = time.time()\n",
    "            print(f'Epoch [{epoch+1}/{epochs}]')\n",
    "            len_X_val = 0 if X_val is None else len(X_val)\n",
    "            len_X_train = len(X_train)\n",
    "            pbar = tf.keras.utils.Progbar(len_X_train + len_X_val)\n",
    "            \n",
    "            total_loss, total_metric1, total_metric2, total_metric3 = 0, 0, 0, 0\n",
    "\n",
    "            # Train\n",
    "            \n",
    "            for num_batch, batch in enumerate(X_train):\n",
    "                img_tensor, features_tensor = batch[0], batch[1]\n",
    "                features_tensor_origi = features_tensor\n",
    "                patients = [dict_['Patient'] for dict_ in features_tensor]\n",
    "                target_original = [self.dict_train_sequence_fvc[patient] for patient in patients]\n",
    "                initial_fvc = [self.dict_patients_train_ini_features[patient]['FVC'] for patient in patients]\n",
    "                target = tf.convert_to_tensor(target_original, dtype=np.float32)\n",
    "#                 print(features_tensor[0]['WeeksSinceLastVisit'])\n",
    "                features_tensor = tf.convert_to_tensor([[p['Sex'], \n",
    "                                                         p['SmokingStatus'],\n",
    "                                                         # p['kind'],\n",
    "                                                         p['Age'],\n",
    "                                                         p['Percent'],\n",
    "                                                         p['WeeksSinceLastVisit'],\n",
    "                                                         # p['FVC_Percent'],\n",
    "                                                         initial_fvc[0]] for p in features_tensor], dtype=tf.float32)\n",
    "                    \n",
    "                weeks_since_lastvisit_tensor = tf.convert_to_tensor(\n",
    "                                                     [self.dict_train_sequence_weekssincelastvisit[patient] for patient in patients], \n",
    "                                                    dtype=tf.float32)\n",
    "                weeks_since_lastvisit_tensor = tf.reshape(weeks_since_lastvisit_tensor, \n",
    "                                                          [weeks_since_lastvisit_tensor.shape[1], 1])\n",
    "                \n",
    "                weeks_since_firstvisit_tensor = tf.convert_to_tensor(\n",
    "                                                     [self.dict_train_sequence_cumweeks[patient] for patient in patients], \n",
    "                                                    dtype=tf.float32)\n",
    "                weeks_since_firstvisit_tensor = tf.reshape(weeks_since_firstvisit_tensor, \n",
    "                                                          [weeks_since_firstvisit_tensor.shape[1], 1])\n",
    "\n",
    "                batch_loss, list_predictions, total_metrics = self.trainStep(img_tensor, \n",
    "                                                                        features_tensor, \n",
    "                                                                        weeks_since_lastvisit_tensor,\n",
    "                                                                        weeks_since_firstvisit_tensor,\n",
    "                                                                        tf.convert_to_tensor([initial_fvc],dtype=tf.float32),\n",
    "                                                                        tf.convert_to_tensor(features_tensor_origi[0]['WeeksSinceLastVisit'],dtype=tf.float32),\n",
    "                                                                        tf.convert_to_tensor(features_tensor_origi[0]['WeeksSinceLastVisit'],dtype=tf.float32),\n",
    "                                                                        target)\n",
    "                \n",
    "                total_loss += batch_loss\n",
    "                metric, mse, metric_last3 = total_metrics[0], total_metrics[1], total_metrics[2]\n",
    "                total_metric1 += metric\n",
    "                total_metric2 += mse\n",
    "                total_metric3 += metric_last3\n",
    "\n",
    "                pbar.update(num_batch + 1, values=[('Loss', batch_loss)] + \\\n",
    "                                                  [('Metric', metric)] + \\\n",
    "                                                  [('Metrict3Timesteps', metric_last3)] + \\\n",
    "                                                  [('mse', mse)])\n",
    "                \n",
    "            self.epsilon = self.epsilon * self.epsilon_decay\n",
    "            total_loss  /= float(len_X_train)\n",
    "            total_metric1  /= float(len_X_train)\n",
    "            history['loss'].append(total_loss)\n",
    "            history['metric'].append(total_metric1)\n",
    "            \n",
    "            # Validation\n",
    "            if X_val:\n",
    "                val_total_loss, val_total_metric, val_total_metric2 = 0, 0, 0\n",
    "                for num_batch, batch in enumerate(X_val):\n",
    "                    img_tensor, features_tensor = batch[0], batch[1]\n",
    "                    features_tensor_origi = features_tensor\n",
    "                    patients = [dict_['Patient'] for dict_ in features_tensor]\n",
    "                    target_original = [self.dict_train_sequence_fvc[patient] for patient in patients]\n",
    "                    initial_fvc = [self.dict_patients_train_ini_features[patient]['FVC'] for patient in patients]\n",
    "                    target = tf.convert_to_tensor(target_original, dtype=np.float32)\n",
    "                    features_tensor = tf.convert_to_tensor([[p['Sex'], \n",
    "                                                             p['SmokingStatus'],\n",
    "                                                             # p['kind'],\n",
    "                                                             p['Age'],\n",
    "                                                             p['Percent'],\n",
    "                                                             p['WeeksSinceLastVisit'],\n",
    "                                                             # p['FVC_Percent'],\n",
    "                                                             initial_fvc[0]] for p in features_tensor], dtype=tf.float32)\n",
    "\n",
    "                    weeks_since_lastvisit_tensor = tf.convert_to_tensor(\n",
    "                                                     [self.dict_train_sequence_weekssincelastvisit[patient] for patient in patients], \n",
    "                                                    dtype=tf.float32)\n",
    "                    weeks_since_lastvisit_tensor = tf.reshape(weeks_since_lastvisit_tensor, \n",
    "                                                          [weeks_since_lastvisit_tensor.shape[1], 1])\n",
    "                    \n",
    "                    weeks_since_firstvisit_tensor = tf.convert_to_tensor(\n",
    "                                                     [self.dict_train_sequence_cumweeks[patient] for patient in patients], \n",
    "                                                    dtype=tf.float32)\n",
    "                    weeks_since_firstvisit_tensor = tf.reshape(weeks_since_firstvisit_tensor, \n",
    "                                                          [weeks_since_firstvisit_tensor.shape[1], 1])\n",
    "                     \n",
    "                    dict_output_tensors = self.predictStep(img_tensor, \n",
    "                                                            features_tensor, \n",
    "                                                            weeks_since_lastvisit_tensor,\n",
    "                                                            weeks_since_firstvisit_tensor,\n",
    "                                                            tf.convert_to_tensor([initial_fvc],dtype=tf.float32),\n",
    "                                                            tf.convert_to_tensor(features_tensor_origi[0]['WeeksSinceLastVisit'],dtype=tf.float32),\n",
    "                                                            tf.convert_to_tensor(features_tensor_origi[0]['WeeksSinceLastVisit'],dtype=tf.float32),\n",
    "                                                            target)\n",
    "    \n",
    "                    predictions = dict_output_tensors['predictions']\n",
    "                    confidences = dict_output_tensors['confidence']\n",
    "                    outputs = dict_output_tensors['outputs']\n",
    "            \n",
    "                    val_q_loss = tf.reduce_mean(outputs)\n",
    "            \n",
    "                    val_metric1 = self.custom_metric(unscale(target, self.mean_fvc, self.std_fvc), \n",
    "                                                        unscale(predictions, self.mean_fvc, self.std_fvc), \n",
    "                                                        std=confidences[:])\n",
    "                                \n",
    "                    val_metric2 = self.custom_metric(unscale(target[:, -3:], self.mean_fvc, self.std_fvc),\n",
    "                                                           unscale(predictions[-3:], self.mean_fvc, self.std_fvc), \n",
    "                                                           std=confidences[-3:])\n",
    "                    val_metric3 = self.metric[0](target, predictions)\n",
    "                    \n",
    "                    val_batch_loss = (val_q_loss * self.lambda_factor) + (val_metric1 * (1-self.lambda_factor))\n",
    "                    \n",
    "                    val_total_loss += val_batch_loss\n",
    "                    val_total_metric += val_metric1\n",
    "                    val_total_metric2 += val_metric2\n",
    "                    \n",
    "                    pbar.update(len_X_train + num_batch + 1, values=[('val_Loss', val_batch_loss)] + \\\n",
    "                                                                    [('val_Metric', val_metric1)] + \\\n",
    "                                                                    [('val_Metrict3Timesteps', val_metric2)] + \\\n",
    "                                                                    [('val_mse', val_metric3)])\n",
    "                    \n",
    "                val_total_loss  /= float(len_X_val)\n",
    "                val_total_metric /= float(len_X_val)\n",
    "                val_total_metric2 /= float(len_X_val)\n",
    "                history['val_loss'].append(val_total_loss)\n",
    "                history['val_metric'].append(val_total_metric)\n",
    "                history['val_Metrict3Timesteps'].append(val_total_metric2)\n",
    "            \n",
    "            self.learningRateDecay(epoch)\n",
    "            X_train.on_epoch_end() \n",
    "            if X_val:\n",
    "                X_val.on_epoch_end()\n",
    "            if self.save_checkpoints:\n",
    "                self.ckpt_manager.save()\n",
    "            print(' ({:.0f} sec)\\n'.format( time.time() - start))\n",
    "            \n",
    "        return history\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def predictStep(self, img_tensor, features_tensor, weeks_since_lastvisit_tensor, weeks_since_firstvisit_tensor,\n",
    "                    initial_fvc, initial_weeks_since_lastvisit_tensor, initial_weeks_since_firstvisit_tensor, \n",
    "                    target=None):\n",
    "        \n",
    "        output_tensors = {}\n",
    "        list_predictions, list_condidences, list_outputs, list_pred_outputs = [], [], [], []\n",
    "        decoder_input = tf.convert_to_tensor([[initial_fvc[0, 0], \n",
    "                                               initial_fvc[0, 0],\n",
    "                                               initial_fvc[0, 0],\n",
    "                                               weeks_since_lastvisit_tensor[0, 0],\n",
    "                                               weeks_since_firstvisit_tensor[0, 0]]], dtype=np.float32)\n",
    "\n",
    "        encoder_features_tensor, encoder_state = self.encoder(img_tensor, \n",
    "                                                              features_tensor,\n",
    "                                                              training=False)\n",
    "        hidden = encoder_state\n",
    "        attention_plot = []\n",
    "        for i in range(0, weeks_since_lastvisit_tensor.shape[0]):\n",
    "            pred_output, hidden, attention_weights = self.decoder(decoder_input, \n",
    "                                                                encoder_features_tensor, \n",
    "                                                                initial_state=encoder_state,\n",
    "                                                                hidden=hidden,\n",
    "                                                                training=False)\n",
    "                                    \n",
    "            pred_std = unscale(pred_output[:, 2], self.mean_fvc, self.std_fvc) - unscale(pred_output[:, 0], self.mean_fvc, self.std_fvc)\n",
    "            pred_mean = pred_output[:, 1]\n",
    "            \n",
    "            if target is not None:\n",
    "                list_outputs.append(self.loss_function(self.quantiles,\n",
    "                                                       unscale(target[:, i], self.mean_fvc, self.std_fvc),\n",
    "                                                       unscale(pred_output, self.mean_fvc, self.std_fvc)))\n",
    "                            \n",
    "            attention_plot.append(tf.reshape(attention_weights, (-1, ))) \n",
    "            list_predictions.append(pred_mean)\n",
    "            list_condidences.append(pred_std)\n",
    "            list_pred_outputs.append(pred_output)\n",
    "       \n",
    "            if i <= weeks_since_lastvisit_tensor.shape[0]:\n",
    "                decoder_input = tf.expand_dims(tf.concat([pred_output[:, 0],\n",
    "                                                          pred_mean,\n",
    "                                                          pred_output[:, 2],\n",
    "                                                          weeks_since_lastvisit_tensor[i],\n",
    "                                                          weeks_since_firstvisit_tensor[i]], axis=-1), 0)    \n",
    "            \n",
    "        output_tensors['predictions'] = tf.convert_to_tensor(list_predictions, dtype=tf.float32)\n",
    "        pred_output_tensor = tf.convert_to_tensor(list_outputs, dtype=tf.float32)\n",
    "        output_tensors['outputs'] = pred_output_tensor\n",
    "        confidences_tensor = tf.convert_to_tensor(list_condidences, dtype=tf.float32)\n",
    "        \n",
    "        output_tensors['confidence'] = tf.reshape(confidences_tensor, (confidences_tensor.shape[0],\n",
    "                                                                       confidences_tensor.shape[1]))\n",
    "        output_tensors['attention_plot'] = tf.convert_to_tensor(attention_plot, dtype=tf.float32)\n",
    "        output_tensors['pred_outputs'] = tf.convert_to_tensor(list_pred_outputs, dtype=tf.float32)\n",
    "        return output_tensors\n",
    "\n",
    "    \n",
    "    def predictEvaluateModel(self, patient, initial_fvc, \n",
    "                             list_weeks_elapsed, list_weeks_since_firstvisit, \n",
    "                             X_generator=None, batch=None):\n",
    "        if not batch:\n",
    "            batch = X_generator.getOnePatient(patient)\n",
    "        img_tensor, features_tensor = batch[0], batch[1]\n",
    "        features_tensor_origi = features_tensor\n",
    "        features_tensor = tf.convert_to_tensor([[p['Sex'], \n",
    "                                                 p['SmokingStatus'],\n",
    "                                                 # p['kind'],\n",
    "                                                 p['Age'],\n",
    "                                                 p['Percent'],\n",
    "                                                 p['WeeksSinceLastVisit'],\n",
    "                                                 # p['FVC_Percent'],\n",
    "                                                 initial_fvc[0]] for p in features_tensor], dtype=tf.float32)\n",
    "        \n",
    "        weeks_since_lastvisit_tensor = tf.convert_to_tensor([list_weeks_elapsed], dtype=tf.float32)\n",
    "        weeks_since_lastvisit_tensor = tf.reshape(weeks_since_lastvisit_tensor, [weeks_since_lastvisit_tensor.shape[1], 1])\n",
    "        \n",
    "        weeks_since_firstvisit_tensor = tf.convert_to_tensor([list_weeks_since_firstvisit], dtype=tf.float32)\n",
    "        weeks_since_firstvisit_tensor = tf.reshape(weeks_since_firstvisit_tensor, [weeks_since_firstvisit_tensor.shape[1], 1])\n",
    "         \n",
    "        dict_output_tensors = self.predictStep(img_tensor, \n",
    "                                                features_tensor, \n",
    "                                                weeks_since_lastvisit_tensor,\n",
    "                                                weeks_since_firstvisit_tensor,\n",
    "                                                tf.convert_to_tensor([initial_fvc], dtype=tf.float32),\n",
    "                                                tf.convert_to_tensor(features_tensor_origi[0]['WeeksSinceLastVisit'],dtype=tf.float32),\n",
    "                                                tf.convert_to_tensor(features_tensor_origi[0]['WeeksSinceLastVisit'],dtype=tf.float32),)\n",
    "        \n",
    "        list_predictions, attention_plot = dict_output_tensors['predictions'], dict_output_tensors['attention_plot']\n",
    "        list_confidences = dict_output_tensors['confidence']\n",
    "        attention_plot = attention_plot[:len(list_predictions)]\n",
    "        list_pred_output = dict_output_tensors['pred_outputs']\n",
    "        \n",
    "        return list_predictions, list_confidences, attention_plot, list_pred_output\n",
    "    \n",
    "           \n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Weights Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "\n",
    "def mloss(_lambda):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = unscale(y_true, mean_fvc, std_fvc)\n",
    "        y_pred = unscale(y_pred, mean_fvc, std_fvc)\n",
    "        return _lambda * quantileLoss(tf.constant([0.2, 0.5, 0.8]), y_true, y_pred) + (1 - _lambda)*customLossFunction(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def buildModel(num_inputs, lambda_factor):\n",
    "    z = layers.Input((num_inputs,), name=\"Patient\")\n",
    "    x = layers.Dense(64, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4), name=\"d1\")(z)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(32, activation=\"relu\", kernel_regularizer=regularizers.l2(1e-4), name=\"d2\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    p1 = layers.Dense(3, activation=\"linear\", name=\"p1\")(x)\n",
    "    p2 = layers.Dense(3, activation=\"relu\", name=\"p2\")(x)\n",
    "    preds = layers.Lambda(lambda x: x[0] + tf.cumsum(x[1], axis=1), \n",
    "                     name=\"preds\")([p1, p2])\n",
    "\n",
    "    model = models.Model(z, p1, name=\"CNN\")\n",
    "    model_loss = mloss(lambda_factor)\n",
    "    model.compile(loss=model_loss, \n",
    "                  optimizer=tf.keras.optimizers.Adam(lr=8e-4, beta_1=0.9, beta_2=0.999, epsilon=None,\n",
    "                                                     amsgrad=False, clipvalue=0.5), \n",
    "                  metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def buildDataSet(list_patients, dict_ini_features, dict_seq_weeks, dict_seq_cumweeks, \n",
    "                 training=True, predictions=None):\n",
    "    \n",
    "    dict_to_tree = {\n",
    "        'Patient' : [],\n",
    "        'Weeks_Elapsed_since_firstVisit': [],\n",
    "        'Base_Percent' : [],\n",
    "        'Age' : [],\n",
    "        'Sex' : [],\n",
    "        'Base_Week' : [],\n",
    "        'Base_FVC' : [],\n",
    "        'Curr_Smokes' : [],\n",
    "        'Ex_Smoker' : [],\n",
    "        'Never_Smoked' : []\n",
    "    }\n",
    "\n",
    "    if training:\n",
    "        dict_to_tree['fvc_real'] = []\n",
    "        # dict_to_tree['kind'] = []\n",
    "    \n",
    "\n",
    "    for patient in tqdm(list_patients, position=0):\n",
    "        \n",
    "        dict_to_tree['Weeks_Elapsed_since_firstVisit'].extend([dict_seq_cumweeks[patient][i] \\\n",
    "                                            for i in range(len(dict_seq_cumweeks[patient]))])\n",
    "        \n",
    "        for i in range(len(dict_seq_weeks[patient])):\n",
    "            dict_to_tree['Patient'].extend([patient])\n",
    "\n",
    "            dict_to_tree['Base_Percent'].extend([dict_ini_features[patient]['Percent']])\n",
    "\n",
    "            dict_to_tree['Age'].extend([dict_ini_features[patient]['Age']])\n",
    "\n",
    "            dict_to_tree['Sex'].extend([dict_ini_features[patient]['Sex']])\n",
    "\n",
    "            dict_to_tree['Base_Week'].extend([dict_ini_features[patient]['WeeksSinceLastVisit']])\n",
    "\n",
    "            dict_to_tree['Base_FVC'].extend([dict_ini_features[patient]['FVC']])\n",
    "\n",
    "            dict_to_tree['Curr_Smokes'].extend([1 if dict_ini_features[patient]['SmokingStatus']==2 else 0])\n",
    "\n",
    "            dict_to_tree['Ex_Smoker'].extend([1 if dict_ini_features[patient]['SmokingStatus']==0 else 0])\n",
    "\n",
    "            dict_to_tree['Never_Smoked'].extend([1 if dict_ini_features[patient]['SmokingStatus']==1 else 0])\n",
    "            \n",
    "#             if training:\n",
    "#                 dict_to_tree['kind'].extend([dict_ini_features[patient]['kind']])\n",
    "\n",
    "        list_weeks_elapsed = list(dict_seq_weeks[patient])\n",
    "        list_weeks_cum = list(dict_seq_cumweeks[patient])\n",
    "\n",
    "        if training:\n",
    "            dict_to_tree['fvc_real'].extend(dict_train_sequence_fvc[patient])\n",
    "\n",
    "    df_tree = pd.DataFrame.from_dict(dict_to_tree, orient='columns')\n",
    "    \n",
    "    return df_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = dict(\n",
    "    # Encoder\n",
    "    encoder_tabular_dense_dim=32, \n",
    "    encoder_tabular_dropout_rate=0.3,\n",
    "    encoder_tabular_sex_dim=20, \n",
    "    encoder_tabular_smoker_dim=20,\n",
    "    encoder_feature_dim = 128,\n",
    "    encoder_unet=False,\n",
    "    encoder_path_unet=path_models + 'encoder_unet3d_v0.2.h5', #'encoder_unet3d.h5',\n",
    "    encoder_resnet=True,\n",
    "    encoder_path_resnet=path_models + 'customModel',#'resnet3D.h5',\n",
    "    encoder_dropout_rate=[0, 0],\n",
    "    encoder_recurrent_max_norm=0.1,\n",
    "    encoder_max_norm=0.1,\n",
    "    # Decoder\n",
    "    decoder_embedding_dim = 128, \n",
    "    decoder_rnn_units = [128], \n",
    "    decoder_dense_units = [],\n",
    "    decoder_dense_activation=None,\n",
    "    decoder_dropout_rate=[0, 0],\n",
    "    decoder_max_norm=0.1,\n",
    "    decoder_recurrent_max_norm=0.1,\n",
    "    decoder_attention_max_norm=0.1,\n",
    "    # Training\n",
    "    learning_rate = 8e-4,\n",
    "    clipvalue=1.0,\n",
    "    teacher_forcing = 'decay', # avg/random/decay\n",
    "    batch_size=1, \n",
    "    epsilon=0, \n",
    "    epsilon_decay=0,\n",
    "    quantiles=[0.2, 0.5, 0.8],\n",
    "    lambda_factor=0.7,\n",
    "    beta_factor=0.8, # How much we weight the last 3 timesteps over the others\n",
    "    # Utils\n",
    "    first_epoch_learning_rate_epoch_decay= 0.9,\n",
    "    constant_learning_rate_epoch_decay= 0.9,\n",
    "    checkpoint_path=path_models + 'checkpoints_gpu_v0.2/model_cv/',\n",
    "    save_checkpoints=False,\n",
    "    restore_last_checkpoint=False, #True if you want to load last execution weights.\n",
    "    # Data Handlers\n",
    "    mean_fvc=mean_fvc,\n",
    "    std_fvc=std_fvc,\n",
    "    dict_train_sequence_fvc=dict_train_sequence_fvc,\n",
    "    dict_train_sequence_weekssincelastvisit=dict_train_sequence_weekssincelastvisit,\n",
    "    dict_train_sequence_cumweeks=dict_train_sequence_cumweeks,\n",
    "    dict_train_patients_masks_paths=dict_train_patients_masks_paths,\n",
    "    dict_patients_train_ini_features=dict_patients_train_ini_features\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Fold: 1\n",
      "Train patients: 150, Test patients: 26\n",
      "Epoch [1/10]\n",
      "WARNING:tensorflow:Layer Encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "176/176 [==============================] - 138s 784ms/step - Loss: 150.2137 - Metric: 7.9884 - Metrict3Timesteps: 8.0359 - mse: 0.5976 - val_Loss: 70.3465 - val_Metric: 7.3099 - val_Metrict3Timesteps: 7.4503 - val_mse: 0.1190\n",
      " (138 sec)\n",
      "\n",
      "Epoch [2/10]\n",
      "176/176 [==============================] - 104s 591ms/step - Loss: 76.4167 - Metric: 7.1802 - Metrict3Timesteps: 7.2908 - mse: 0.1494 - val_Loss: 58.5392 - val_Metric: 7.0575 - val_Metrict3Timesteps: 7.3221 - val_mse: 0.1026\n",
      " (104 sec)\n",
      "\n",
      "Epoch [3/10]\n",
      "176/176 [==============================] - 104s 592ms/step - Loss: 64.1602 - Metric: 7.0519 - Metrict3Timesteps: 7.1680 - mse: 0.0987 - val_Loss: 55.9160 - val_Metric: 7.0507 - val_Metrict3Timesteps: 7.3311 - val_mse: 0.0931\n",
      " (104 sec)\n",
      "\n",
      "Epoch [4/10]\n",
      "176/176 [==============================] - 105s 596ms/step - Loss: 60.3219 - Metric: 6.9663 - Metrict3Timesteps: 7.0922 - mse: 0.0926 - val_Loss: 64.6086 - val_Metric: 7.1904 - val_Metrict3Timesteps: 7.4524 - val_mse: 0.1336\n",
      " (105 sec)\n",
      "\n",
      "Epoch [5/10]\n",
      "176/176 [==============================] - 105s 595ms/step - Loss: 60.3963 - Metric: 6.9563 - Metrict3Timesteps: 7.0776 - mse: 0.0954 - val_Loss: 56.2628 - val_Metric: 7.0851 - val_Metrict3Timesteps: 7.2835 - val_mse: 0.1007\n",
      " (105 sec)\n",
      "\n",
      "Epoch [6/10]\n",
      "176/176 [==============================] - 104s 589ms/step - Loss: 57.5896 - Metric: 6.9503 - Metrict3Timesteps: 7.0520 - mse: 0.0874 - val_Loss: 58.8911 - val_Metric: 7.0573 - val_Metrict3Timesteps: 7.1193 - val_mse: 0.1081\n",
      " (104 sec)\n",
      "\n",
      "Epoch [7/10]\n",
      "176/176 [==============================] - 103s 586ms/step - Loss: 59.4946 - Metric: 6.9415 - Metrict3Timesteps: 7.0700 - mse: 0.0908 - val_Loss: 54.0370 - val_Metric: 6.9809 - val_Metrict3Timesteps: 7.2574 - val_mse: 0.0967\n",
      " (103 sec)\n",
      "\n",
      "Epoch [8/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 57.2226 - Metric: 6.8807 - Metrict3Timesteps: 7.0149 - mse: 0.0864 - val_Loss: 53.9325 - val_Metric: 6.9364 - val_Metrict3Timesteps: 7.2461 - val_mse: 0.0873\n",
      " (103 sec)\n",
      "\n",
      "Epoch [9/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 57.0771 - Metric: 6.8745 - Metrict3Timesteps: 7.0151 - mse: 0.0835 - val_Loss: 53.6344 - val_Metric: 6.9933 - val_Metrict3Timesteps: 7.2179 - val_mse: 0.0917\n",
      " (103 sec)\n",
      "\n",
      "Epoch [10/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 58.0197 - Metric: 6.9062 - Metrict3Timesteps: 7.0469 - mse: 0.0885 - val_Loss: 54.4232 - val_Metric: 6.9979 - val_Metrict3Timesteps: 7.1051 - val_mse: 0.0926\n",
      " (103 sec)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 150/150 [00:00<00:00, 49672.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 26082.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 235.9942 - mae: 0.7403 - val_loss: 84.4929 - val_mae: 0.4619\n",
      "Epoch 2/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 160.8118 - mae: 0.5478 - val_loss: 71.2544 - val_mae: 0.3478\n",
      "Epoch 3/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 143.1885 - mae: 0.4625 - val_loss: 66.1769 - val_mae: 0.3131\n",
      "Epoch 4/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 133.1765 - mae: 0.4297 - val_loss: 65.1623 - val_mae: 0.3050\n",
      "Epoch 5/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 128.0603 - mae: 0.4088 - val_loss: 62.9254 - val_mae: 0.2996\n",
      "Epoch 6/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 125.8769 - mae: 0.4026 - val_loss: 61.9238 - val_mae: 0.2969\n",
      "Epoch 7/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 120.8713 - mae: 0.3854 - val_loss: 61.5527 - val_mae: 0.2896\n",
      "Epoch 8/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 116.2465 - mae: 0.3656 - val_loss: 60.1775 - val_mae: 0.2840\n",
      "Epoch 9/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 113.1383 - mae: 0.3596 - val_loss: 58.5294 - val_mae: 0.2741\n",
      "Epoch 10/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 109.9794 - mae: 0.3523 - val_loss: 59.1206 - val_mae: 0.2794\n",
      "Epoch 11/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 105.8802 - mae: 0.3379 - val_loss: 58.9562 - val_mae: 0.2802\n",
      "Epoch 12/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 107.0667 - mae: 0.3444 - val_loss: 58.0972 - val_mae: 0.2696\n",
      "Epoch 13/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 103.2165 - mae: 0.3241 - val_loss: 58.4375 - val_mae: 0.2729\n",
      "Epoch 14/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 105.8670 - mae: 0.3334 - val_loss: 57.0230 - val_mae: 0.2684\n",
      "Epoch 15/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 101.5186 - mae: 0.3209 - val_loss: 57.2061 - val_mae: 0.2686\n",
      "Epoch 16/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 100.4181 - mae: 0.3200 - val_loss: 57.7004 - val_mae: 0.2730\n",
      "Epoch 17/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 100.8855 - mae: 0.3184 - val_loss: 58.0679 - val_mae: 0.2771\n",
      "Epoch 18/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 100.6453 - mae: 0.3187 - val_loss: 58.6605 - val_mae: 0.2801\n",
      "Epoch 19/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 102.9025 - mae: 0.3283 - val_loss: 58.4980 - val_mae: 0.2793\n",
      "Epoch 20/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 99.0808 - mae: 0.3133 - val_loss: 57.4307 - val_mae: 0.2753\n",
      "Epoch 21/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 99.2303 - mae: 0.3103 - val_loss: 59.0547 - val_mae: 0.2779\n",
      "Epoch 22/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 93.4926 - mae: 0.2994 - val_loss: 58.0243 - val_mae: 0.2744\n",
      "Epoch 23/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 97.6288 - mae: 0.3092 - val_loss: 59.6202 - val_mae: 0.2824\n",
      "Epoch 24/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 98.0986 - mae: 0.3117 - val_loss: 59.5270 - val_mae: 0.2819\n",
      "Epoch 25/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 98.0404 - mae: 0.3069 - val_loss: 58.5465 - val_mae: 0.2784\n",
      "Epoch 26/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 98.6582 - mae: 0.3122 - val_loss: 56.4559 - val_mae: 0.2819\n",
      "Epoch 27/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 97.7039 - mae: 0.3068 - val_loss: 55.3727 - val_mae: 0.2657\n",
      "Epoch 28/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 94.3605 - mae: 0.3008 - val_loss: 57.3109 - val_mae: 0.2736\n",
      "Epoch 29/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 98.6610 - mae: 0.3125 - val_loss: 55.9056 - val_mae: 0.2747\n",
      "Epoch 30/30\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 95.1567 - mae: 0.2997 - val_loss: 54.8521 - val_mae: 0.2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/26 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric weights model: 6.956005096435547, 7.138147830963135\n",
      "******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:18<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric base model: 6.894548416137695, 7.08143949508667\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "Metric ensembled model: 6.867088317871094, 7.060805320739746\n",
      "******************************************************************************************\n",
      "Num Fold: 2\n",
      "Train patients: 151, Test patients: 25\n",
      "Epoch [1/10]\n",
      "WARNING:tensorflow:Layer Encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      " 14/176 [=>............................] - ETA: 6:40 - Loss: 177.1637 - Metric: 9.8887 - Metrict3Timesteps: 9.8024 - mse: 0.7054 WARNING:tensorflow:5 out of the last 15 calls to <function PulmonarFibrosisEncoderDecoder.trainStep at 0x0000021B215349D8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "152/176 [========================>.....] - ETA: 19s - Loss: 136.5989 - Metric: 7.9728 - Metrict3Timesteps: 8.0095 - mse: 0.5049 - val_Loss: 122.9605 - val_Metric: 7.9360 - val_Metrict3Timesteps: 8.2569 - val_mse: 0.4053WARNING:tensorflow:5 out of the last 17 calls to <function PulmonarFibrosisEncoderDecoder.predictStep at 0x0000021B6B630EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "154/176 [=========================>....] - ETA: 17s - Loss: 136.5989 - Metric: 7.9728 - Metrict3Timesteps: 8.0095 - mse: 0.5049 - val_Loss: 89.6836 - val_Metric: 7.6250 - val_Metrict3Timesteps: 7.8708 - val_mse: 0.2552 WARNING:tensorflow:5 out of the last 11 calls to <function PulmonarFibrosisEncoderDecoder.predictStep at 0x0000021B6B630EE8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "176/176 [==============================] - 139s 789ms/step - Loss: 136.5989 - Metric: 7.9728 - Metrict3Timesteps: 8.0095 - mse: 0.5049 - val_Loss: 83.4441 - val_Metric: 7.4403 - val_Metrict3Timesteps: 7.5123 - val_mse: 0.1983\n",
      " (139 sec)\n",
      "\n",
      "Epoch [2/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 75.6193 - Metric: 7.2308 - Metrict3Timesteps: 7.3110 - mse: 0.1384 - val_Loss: 72.6711 - val_Metric: 7.2060 - val_Metrict3Timesteps: 7.3578 - val_mse: 0.1562\n",
      " (103 sec)\n",
      "\n",
      "Epoch [3/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 62.6650 - Metric: 7.0099 - Metrict3Timesteps: 7.1182 - mse: 0.0988 - val_Loss: 69.1040 - val_Metric: 7.1533 - val_Metrict3Timesteps: 7.4273 - val_mse: 0.1386\n",
      " (103 sec)\n",
      "\n",
      "Epoch [4/10]\n",
      "176/176 [==============================] - 103s 586ms/step - Loss: 61.4646 - Metric: 6.9642 - Metrict3Timesteps: 7.0963 - mse: 0.0952 - val_Loss: 67.4938 - val_Metric: 7.1194 - val_Metrict3Timesteps: 7.4361 - val_mse: 0.1468\n",
      " (103 sec)\n",
      "\n",
      "Epoch [5/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 56.9041 - Metric: 6.9070 - Metrict3Timesteps: 7.0307 - mse: 0.0811 - val_Loss: 71.7968 - val_Metric: 7.1365 - val_Metrict3Timesteps: 7.4096 - val_mse: 0.1699\n",
      " (103 sec)\n",
      "\n",
      "Epoch [6/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 57.4741 - Metric: 6.9141 - Metrict3Timesteps: 7.0407 - mse: 0.0861 - val_Loss: 63.3699 - val_Metric: 7.0639 - val_Metrict3Timesteps: 7.3385 - val_mse: 0.1354\n",
      " (103 sec)\n",
      "\n",
      "Epoch [7/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 56.0406 - Metric: 6.8884 - Metrict3Timesteps: 7.0178 - mse: 0.0797 - val_Loss: 60.1590 - val_Metric: 7.0288 - val_Metrict3Timesteps: 7.2668 - val_mse: 0.1147\n",
      " (103 sec)\n",
      "\n",
      "Epoch [8/10]\n",
      "176/176 [==============================] - 103s 586ms/step - Loss: 55.8711 - Metric: 6.8796 - Metrict3Timesteps: 7.0102 - mse: 0.0771 - val_Loss: 59.8268 - val_Metric: 7.0614 - val_Metrict3Timesteps: 7.2836 - val_mse: 0.1207\n",
      " (103 sec)\n",
      "\n",
      "Epoch [9/10]\n",
      "176/176 [==============================] - 105s 595ms/step - Loss: 55.6748 - Metric: 6.8421 - Metrict3Timesteps: 6.9951 - mse: 0.0778 - val_Loss: 59.7880 - val_Metric: 7.0322 - val_Metrict3Timesteps: 7.2637 - val_mse: 0.1137\n",
      " (105 sec)\n",
      "\n",
      "Epoch [10/10]\n",
      "176/176 [==============================] - 103s 587ms/step - Loss: 54.4509 - Metric: 6.8537 - Metrict3Timesteps: 6.9883 - mse: 0.0760 - val_Loss: 65.1233 - val_Metric: 7.0970 - val_Metrict3Timesteps: 7.3269 - val_mse: 0.1322\n",
      " (103 sec)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 50489.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 25061.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "74/74 [==============================] - 0s 3ms/step - loss: 229.9944 - mae: 0.6688 - val_loss: 118.9727 - val_mae: 0.5738\n",
      "Epoch 2/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 146.8439 - mae: 0.4930 - val_loss: 83.9989 - val_mae: 0.4076\n",
      "Epoch 3/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 137.3419 - mae: 0.4410 - val_loss: 76.4976 - val_mae: 0.3794\n",
      "Epoch 4/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 122.1851 - mae: 0.3983 - val_loss: 76.2941 - val_mae: 0.3359\n",
      "Epoch 5/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 118.2038 - mae: 0.3747 - val_loss: 73.4093 - val_mae: 0.3462\n",
      "Epoch 6/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 116.1309 - mae: 0.3717 - val_loss: 73.6545 - val_mae: 0.3293\n",
      "Epoch 7/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 115.4221 - mae: 0.3693 - val_loss: 69.9670 - val_mae: 0.3254\n",
      "Epoch 8/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 110.3744 - mae: 0.3495 - val_loss: 72.7713 - val_mae: 0.3192\n",
      "Epoch 9/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 103.8988 - mae: 0.3392 - val_loss: 68.9929 - val_mae: 0.3110\n",
      "Epoch 10/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 108.6015 - mae: 0.3429 - val_loss: 68.3415 - val_mae: 0.3269\n",
      "Epoch 11/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 109.9141 - mae: 0.3607 - val_loss: 67.9174 - val_mae: 0.3107\n",
      "Epoch 12/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 103.1918 - mae: 0.3286 - val_loss: 66.4207 - val_mae: 0.2997\n",
      "Epoch 13/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 104.1024 - mae: 0.3251 - val_loss: 64.3089 - val_mae: 0.2991\n",
      "Epoch 14/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 102.4706 - mae: 0.3276 - val_loss: 66.2907 - val_mae: 0.2961\n",
      "Epoch 15/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 103.0640 - mae: 0.3286 - val_loss: 66.1439 - val_mae: 0.3179\n",
      "Epoch 16/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 97.9874 - mae: 0.3165 - val_loss: 65.0215 - val_mae: 0.2968\n",
      "Epoch 17/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 100.4933 - mae: 0.3219 - val_loss: 65.4274 - val_mae: 0.3089\n",
      "Epoch 18/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 97.0706 - mae: 0.3113 - val_loss: 65.2063 - val_mae: 0.2969\n",
      "Epoch 19/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 97.1296 - mae: 0.3083 - val_loss: 66.5379 - val_mae: 0.3033\n",
      "Epoch 20/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 96.3566 - mae: 0.3071 - val_loss: 66.3578 - val_mae: 0.2989\n",
      "Epoch 21/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 97.0142 - mae: 0.3095 - val_loss: 63.7805 - val_mae: 0.2929\n",
      "Epoch 22/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 98.0380 - mae: 0.3109 - val_loss: 65.6986 - val_mae: 0.2911\n",
      "Epoch 23/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 96.7710 - mae: 0.3057 - val_loss: 64.9310 - val_mae: 0.2963\n",
      "Epoch 24/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 94.3615 - mae: 0.3027 - val_loss: 65.6934 - val_mae: 0.2986\n",
      "Epoch 25/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 93.8153 - mae: 0.2983 - val_loss: 65.6138 - val_mae: 0.2961\n",
      "Epoch 26/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 95.7140 - mae: 0.3054 - val_loss: 66.5029 - val_mae: 0.2980\n",
      "Epoch 27/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 93.3698 - mae: 0.2998 - val_loss: 64.2460 - val_mae: 0.2832\n",
      "Epoch 28/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 92.9770 - mae: 0.2933 - val_loss: 64.5210 - val_mae: 0.2946\n",
      "Epoch 29/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 90.8572 - mae: 0.2886 - val_loss: 64.3017 - val_mae: 0.2849\n",
      "Epoch 30/30\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 93.9071 - mae: 0.2956 - val_loss: 64.6226 - val_mae: 0.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric weights model: 7.040679454803467, 7.2198615074157715\n",
      "******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:16<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric base model: 7.045562744140625, 7.322145938873291\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "Metric ensembled model: 7.0074238777160645, 7.262973785400391\n",
      "******************************************************************************************\n",
      "Num Fold: 3\n",
      "Train patients: 151, Test patients: 25\n",
      "Epoch [1/10]\n",
      "WARNING:tensorflow:Layer Encoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "157/176 [=========================>....] - ETA: 15s - Loss: 144.0643 - Metric: 7.9459 - Metrict3Timesteps: 7.9960 - mse: 0.4966 - val_Loss: 141.4666 - val_Metric: 7.8144 - val_Metrict3Timesteps: 7.9502 - val_mse: 0.4641WARNING:tensorflow:5 out of the last 22 calls to <function PulmonarFibrosisEncoderDecoder.predictStep at 0x0000021BDAF7C168> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "176/176 [==============================] - 145s 826ms/step - Loss: 144.0643 - Metric: 7.9459 - Metrict3Timesteps: 7.9960 - mse: 0.4966 - val_Loss: 119.4893 - val_Metric: 7.6967 - val_Metrict3Timesteps: 7.7439 - val_mse: 0.2836 - Loss: 144.0643 - Metric: 7.9459 - Metrict3Timesteps: 7.9960 - mse: 0.4966 - val_Loss: 116.2546 - val_Metric: 7.6822 - val_Metrict3Timesteps: 7.7253 -\n",
      " (145 sec)\n",
      "\n",
      "Epoch [2/10]\n",
      "176/176 [==============================] - 113s 643ms/step - Loss: 75.6889 - Metric: 7.2216 - Metrict3Timesteps: 7.3133 - mse: 0.1297 - val_Loss: 59.5049 - val_Metric: 7.1114 - val_Metrict3Timesteps: 7.2280 - val_mse: 0.1125\n",
      " (113 sec)\n",
      "\n",
      "Epoch [3/10]\n",
      "176/176 [==============================] - 110s 628ms/step - Loss: 63.5559 - Metric: 7.0399 - Metrict3Timesteps: 7.1768 - mse: 0.0957 - val_Loss: 89.1339 - val_Metric: 7.3596 - val_Metrict3Timesteps: 7.3880 - val_mse: 0.19699s - Loss: 63.5559 - Metric: 7.0399 - Metrict3Timesteps: 7.1768 - mse: 0.0957 - val_Loss: 71.8239 - val_Metric: 7.1945 - val_Metrict3Time\n",
      " (111 sec)\n",
      "\n",
      "Epoch [4/10]\n",
      "176/176 [==============================] - 112s 636ms/step - Loss: 62.2534 - Metric: 6.9812 - Metrict3Timesteps: 7.1264 - mse: 0.0913 - val_Loss: 66.5728 - val_Metric: 7.1600 - val_Metrict3Timesteps: 7.2546 - val_mse: 0.1405\n",
      " (112 sec)\n",
      "\n",
      "Epoch [5/10]\n",
      "176/176 [==============================] - 112s 638ms/step - Loss: 57.7861 - Metric: 6.9136 - Metrict3Timesteps: 7.0460 - mse: 0.0808 - val_Loss: 62.8093 - val_Metric: 7.1547 - val_Metrict3Timesteps: 7.2261 - val_mse: 0.1282\n",
      " (112 sec)\n",
      "\n",
      "Epoch [6/10]\n",
      "176/176 [==============================] - ETA: 0s - Loss: 58.4150 - Metric: 6.9157 - Metrict3Timesteps: 7.0695 - mse: 0.0803 - val_Loss: 60.1408 - val_Metric: 7.1025 - val_Metrict3Timesteps: 7.1550 - val_mse: 0.11 - 114s 648ms/step - Loss: 58.4150 - Metric: 6.9157 - Metrict3Timesteps: 7.0695 - mse: 0.0803 - val_Loss: 59.9735 - val_Metric: 7.1038 - val_Metrict3Timesteps: 7.1589 - val_mse: 0.1165\n",
      " (114 sec)\n",
      "\n",
      "Epoch [7/10]\n",
      " 69/176 [==========>...................] - ETA: 1:04 - Loss: 59.6918 - Metric: 6.9669 - Metrict3Timesteps: 7.0824 - mse: 0.0897"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-561a7875933f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     history = model.fitModel(X_train=X_train_generator, \n\u001b[0;32m     50\u001b[0m                              \u001b[0mX_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_val_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                              epochs=10)\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mplotTrainHistory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Sequence to Sequence Training'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-1d5550edb954>\u001b[0m in \u001b[0;36mfitModel\u001b[1;34m(self, X_train, X_val, epochs)\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mnum_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m                 \u001b[0mimg_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m                 \u001b[0mfeatures_tensor_origi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    484\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m       \u001b[1;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    484\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[1;34m\"\"\"Create a generator that iterate over the Sequence.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m       \u001b[1;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e8e18878cc16>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     48\u001b[0m                                                   \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_size_load\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_size_load\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                                                   numpy=True) \n\u001b[1;32m---> 50\u001b[1;33m                               for patient in patient_ids]\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mlist_scan_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessRawScans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatient_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-e8e18878cc16>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     48\u001b[0m                                                   \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_size_load\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_size_load\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                                                   numpy=True) \n\u001b[1;32m---> 50\u001b[1;33m                               for patient in patient_ids]\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mlist_scan_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessRawScans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatient_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\PROYECTOS\\OSIC Pulmonary - 2020\\02_Scripts\\02_FinalModels\\Utils\\utils.py\u001b[0m in \u001b[0;36mdecodePatientImages\u001b[1;34m(patient, dict_patients_masks_paths, image_size, numpy)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwindowImageNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_bound\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1_000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_bound\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#min_bound=-1_000, max_bound=400\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         img_resized = tf.convert_to_tensor([tf.image.resize(tf.expand_dims(img, axis=2), image_size) for img in imgs], \n\u001b[0m\u001b[0;32m     80\u001b[0m                                            dtype=tf.float32)\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "\n",
    "img_size_load=(260, 260, 1)\n",
    "img_size_crop=(220, 220, 1)\n",
    "num_frames_batch = 32\n",
    "train_alpha = 0.9\n",
    "val_alpha = 0.9\n",
    "batch_size = 1\n",
    "random_window = True\n",
    "\n",
    "ensembled_coeff = 0.75\n",
    "s_w_factor = 2\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 7, random_state = 12, shuffle = True)\n",
    "list_models, list_history = [], []\n",
    "list_models_weights, list_history_weights = [], []\n",
    "list_history_ensembles = []\n",
    "\n",
    "for num_fold, (train_index, val_index) in enumerate(skf.split(unique_train_patients, \n",
    "                                                              np.zeros(unique_train_patients.shape[0]))):\n",
    "\n",
    "    x_train_patients = list(unique_train_patients[train_index])\n",
    "    x_val_patients = list(unique_train_patients[val_index])\n",
    "    \n",
    "    print(f'Num Fold: {num_fold + 1}')\n",
    "    print(f'Train patients: {len(x_train_patients)}, Test patients: {len(x_val_patients)}')    \n",
    "\n",
    "    X_train_generator = SequenceToSequenceDataGenerator(raw_scans=False, training=True, \n",
    "                                                        patients=x_train_patients,\n",
    "                                                        batch_size=batch_size, num_frames_batch=num_frames_batch, \n",
    "                                                        alpha=train_alpha, random_window=random_window, center_crop=True,\n",
    "                                                        img_size_load=img_size_load, img_size_crop=img_size_crop,\n",
    "                                                        dict_ini_features=dict_patients_train_ini_features, \n",
    "                                                        dict_patients_masks_paths=dict_train_patients_masks_paths,\n",
    "                                                        dict_raw_scans_paths=None)\n",
    "\n",
    "    X_val_generator = SequenceToSequenceDataGenerator(raw_scans=False, training=False, \n",
    "                                                      patients=x_val_patients,\n",
    "                                                      batch_size=1, num_frames_batch=num_frames_batch, \n",
    "                                                      alpha=val_alpha, random_window=random_window, center_crop=True,\n",
    "                                                      img_size_load=img_size_load, img_size_crop=img_size_crop,\n",
    "                                                      dict_ini_features=dict_patients_train_ini_features, \n",
    "                                                      dict_patients_masks_paths=dict_train_patients_masks_paths,\n",
    "                                                      dict_raw_scans_paths=None)\n",
    "\n",
    "    model_inputs['num_fold'] = num_fold\n",
    "    model = PulmonarFibrosisEncoderDecoder(**model_inputs)\n",
    "\n",
    "    history = model.fitModel(X_train=X_train_generator, \n",
    "                             X_val=X_val_generator,\n",
    "                             epochs=10)\n",
    "    \n",
    "    plotTrainHistory(history, title='Sequence to Sequence Training', scale=True)\n",
    "    \n",
    "    list_models.append(model)\n",
    "    list_history.append(history)\n",
    "    \n",
    "    ######################\n",
    "    \n",
    "    ## Weights Model\n",
    "    \n",
    "    df_train_weights = buildDataSet(x_train_patients, \n",
    "                 dict_ini_features=dict_patients_train_ini_features, \n",
    "                 dict_seq_weeks=dict_train_sequence_weekssincelastvisit, \n",
    "                 dict_seq_cumweeks=dict_train_sequence_cumweeks, \n",
    "                 training=True, \n",
    "                 predictions=None)\n",
    "\n",
    "    df_val_weights = buildDataSet(x_val_patients,\n",
    "                 dict_ini_features=dict_patients_train_ini_features, \n",
    "                 dict_seq_weeks=dict_train_sequence_weekssincelastvisit, \n",
    "                 dict_seq_cumweeks=dict_train_sequence_cumweeks, \n",
    "                 training=True, \n",
    "                 predictions=None)\n",
    "                                               \n",
    "    features = list(col for col in df_train_weights.columns if col not in ['Patient', 'fvc_real', 'kind'])   \n",
    "    y_train = df_train_weights['fvc_real'].astype(float)\n",
    "    y_val = df_val_weights['fvc_real'].astype(float)\n",
    "\n",
    "    X_train =  df_train_weights[features]\n",
    "    X_val =  df_val_weights[features]\n",
    "\n",
    "    model_weights = buildModel(len(features), lambda_factor=0.75)\n",
    "    \n",
    "    sample_weight = np.ones(shape=df_train_weights.shape[0])\n",
    "    idx_l3 = list(df_train_weights.groupby('Patient').tail(3).index)\n",
    "    sample_weight[idx_l3] = s_w_factor\n",
    "\n",
    "    model_weights.fit(X_train, y_train,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      sample_weight=sample_weight,\n",
    "                      shuffle=True, batch_size=16, \n",
    "                      epochs=30, verbose=1)\n",
    "    \n",
    "    list_models_weights.append(model_weights)\n",
    "    \n",
    "    y_val_pred = model_weights.predict(X_val)\n",
    "    y_val_pred_median = unscale(y_val_pred[:, 1], mean_fvc, std_fvc)\n",
    "    y_val_pred_std = unscale(y_val_pred[:, 2], mean_fvc, std_fvc) - unscale(y_val_pred[:, 0], mean_fvc, std_fvc)\n",
    "\n",
    "    \n",
    "    metric = customLossFunction(unscale(y_val, mean_fvc, std_fvc),\n",
    "                                       y_val_pred_median,\n",
    "                                     y_val_pred_std).numpy()\n",
    "    \n",
    "    X_val_last_3 = df_val_weights.groupby('Patient').tail(3)\n",
    "    y_val_l3 = X_val_last_3['fvc_real']\n",
    "    \n",
    "    y_val_pred_l3 = model_weights.predict(X_val_last_3[features])\n",
    "    y_val_pred_l3_median = unscale(y_val_pred_l3[:, 1], mean_fvc, std_fvc)\n",
    "    y_val_pred_l3_std = unscale(y_val_pred_l3[:, 2], mean_fvc, std_fvc) - unscale(y_val_pred_l3[:, 0], mean_fvc, std_fvc)\n",
    "    \n",
    "    metric_l3 = customLossFunction(unscale(y_val_l3, mean_fvc, std_fvc),\n",
    "                                           y_val_pred_l3_median,\n",
    "                                           y_val_pred_l3_std).numpy()\n",
    "    \n",
    "    list_history_weights.append({'val_metric' : metric, 'val_Metrict3Timesteps' : metric_l3 })\n",
    "    print('***'*30)\n",
    "    print(f'Metric weights model: {metric}, {metric_l3}')\n",
    "    print('***'*30)\n",
    "    \n",
    "    ######################\n",
    "    \n",
    "    # Base model\n",
    "    \n",
    "    list_weights_predictions = y_val_pred_median\n",
    "    list_weights_confidences = y_val_pred_std\n",
    "    list_weights_predictions_l3 = y_val_pred_l3_median\n",
    "    list_weights_confidences_l3 = y_val_pred_l3_std\n",
    "    \n",
    "    list_base_predictions, list_base_confidences = [], []\n",
    "    list_base_predictions_l3, list_base_confidences_l3 = [], []\n",
    "    \n",
    "    for patient in tqdm(x_val_patients, total=len(x_val_patients), position=0):\n",
    "        list_submission_weeks_elapsed = dict_train_sequence_fvc[patient]\n",
    "        list_weeks_since_firstvisit = dict_train_sequence_cumweeks[patient]\n",
    "        base_model_predictions, base_model_stds, _, _ = model.predictEvaluateModel(X_generator=X_val_generator,\n",
    "                                                         patient=patient, \n",
    "                                                         list_weeks_elapsed=list_submission_weeks_elapsed,\n",
    "                                                         list_weeks_since_firstvisit=list_weeks_since_firstvisit,\n",
    "                                                         initial_fvc=[dict_patients_train_ini_features[patient]['FVC']])\n",
    "        \n",
    "        base_model_predictions = unscale(base_model_predictions.numpy().flatten(), mean_fvc, std_fvc)\n",
    "        list_base_predictions.extend(base_model_predictions)\n",
    "        list_base_confidences.extend(base_model_stds.numpy().flatten())\n",
    "        \n",
    "        list_base_predictions_l3.extend(base_model_predictions[-3:])\n",
    "        list_base_confidences_l3.extend(base_model_stds[-3:].numpy().flatten())\n",
    "        \n",
    "    metric_base = customLossFunction(y_true=unscale(y_val, mean_fvc, std_fvc),\n",
    "                                           y_pred=list_base_predictions,\n",
    "                                           std=list_base_confidences)\n",
    "    \n",
    "    metric_base_l3 = customLossFunction(y_true=unscale(y_val_l3, mean_fvc, std_fvc),\n",
    "                                           y_pred=list_base_predictions_l3,\n",
    "                                           std=list_base_confidences_l3)\n",
    "    \n",
    "    print('***'*30)\n",
    "    print(f'Metric base model: {metric_base}, {metric_base_l3}')\n",
    "    print('***'*30)\n",
    "    \n",
    "    ######################\n",
    "    \n",
    "    # Ensembling\n",
    "    \n",
    "    ensembled_predictions = (np.asarray(list_base_predictions) * ensembled_coeff) + (list_weights_predictions * (1-ensembled_coeff))\n",
    "    ensembled_confidences = (np.asarray(list_base_confidences) * ensembled_coeff) + (list_weights_confidences * (1-ensembled_coeff))\n",
    "    \n",
    "    ensembled_predictions_l3 = (np.asarray(list_base_predictions_l3) * ensembled_coeff) + (list_weights_predictions_l3 * (1-ensembled_coeff))\n",
    "    ensembled_confidences_l3 = (np.asarray(list_base_confidences_l3) * ensembled_coeff) + (list_weights_confidences_l3 * (1-ensembled_coeff))\n",
    "    \n",
    "    metric_ensembled = customLossFunction(y_true=unscale(y_val, mean_fvc, std_fvc),\n",
    "                                           y_pred=ensembled_predictions,\n",
    "                                           std=ensembled_confidences)\n",
    "    \n",
    "    metric_ensembled_l3 = customLossFunction(y_true=unscale(y_val_l3, mean_fvc, std_fvc),\n",
    "                                             y_pred=ensembled_predictions_l3,\n",
    "                                             std=ensembled_confidences_l3)\n",
    "    \n",
    "    list_history_ensembles.append({'val_metric' : metric_ensembled, 'val_Metrict3Timesteps' : metric_ensembled_l3})\n",
    "    print('***'*30)\n",
    "    print(f'Metric ensembled model: {metric_ensembled}, {metric_ensembled_l3}')\n",
    "    print('***'*30)\n",
    "    \n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.773247 7.047446 7.21603\n",
      "6.9983425 7.1790047\n",
      "6.937256 7.1618896\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "\n",
    "## Base model\n",
    "\n",
    "base_val_loss = np.mean([history['val_loss'][-1] for history in list_history])\n",
    "base_val_metric = np.mean([(history['val_metric'][-1]) for history in list_history])\n",
    "base_val_metric_last3 = np.mean([(history['val_Metrict3Timesteps'][-1]) for history in list_history])\n",
    "\n",
    "print(base_val_loss, base_val_metric, base_val_metric_last3)\n",
    "\n",
    "## Weights\n",
    "\n",
    "weights_val_metric = np.mean([(history['val_metric']) for history in list_history_weights])\n",
    "weights_val_metric_last3 = np.mean([(history['val_Metrict3Timesteps']) for history in list_history_weights])\n",
    "\n",
    "print(weights_val_metric, weights_val_metric_last3)\n",
    "\n",
    "## Ensemble\n",
    "\n",
    "ensemble_val_metric = np.mean([(history['val_metric']) for history in list_history_ensembles])\n",
    "ensemble_val_metric_last3 = np.mean([(history['val_Metrict3Timesteps']) for history in list_history_ensembles])\n",
    "\n",
    "print(ensemble_val_metric, ensemble_val_metric_last3)\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### History models\n",
    "# 1. ensemble_coeff = 0.5 \n",
    "\n",
    "# 1.4365882 6.866982 6.9187007\n",
    "# 7.0161257 7.116428\n",
    "#-> 6.8267794 6.942761\n",
    "\n",
    "# 2. ensemble_coeff = 0.7 \n",
    "\n",
    "# 1.4366915 6.866254 6.91714\n",
    "# 6.9919753 7.1083403\n",
    "#-> 6.7669153 6.8837447"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 44534.12it/s]\n",
      "  0%|                                                                                          | 0/176 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric sub weights model: 6.910582542419434, 7.029907703399658\n",
      "******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 176/176 [01:42<00:00,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 58834.58it/s]\n",
      "  0%|                                                                                          | 0/176 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric sub base model: 6.917273044586182, 7.020876407623291\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "Metric ensembled model: 6.863484859466553, 6.981986999511719\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "Metric sub weights model: 6.873198509216309, 6.982013702392578\n",
      "******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 176/176 [02:20<00:00,  1.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 58825.21it/s]\n",
      "  0%|                                                                                          | 0/176 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric sub base model: 6.892694473266602, 6.997180938720703\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "Metric ensembled model: 6.849411964416504, 6.967347621917725\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "Metric sub weights model: 6.910279750823975, 7.031265735626221\n",
      "******************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 176/176 [02:25<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************************\n",
      "Metric sub base model: 6.847013473510742, 7.01287841796875\n",
      "******************************************************************************************\n",
      "******************************************************************************************\n",
      "Metric ensembled model: 6.850027561187744, 7.006999969482422\n",
      "******************************************************************************************\n",
      "6.88566 7.0103116\n",
      "6.8980203 7.014395\n",
      "6.8543077 6.985445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_folds = 3\n",
    "ensembled_coeff = 0.7\n",
    "list_base_h = []\n",
    "list_weights_h = []\n",
    "list_ensembled_h = []\n",
    "\n",
    "for n_fold in range(num_folds):\n",
    "    \n",
    "    X_sub_generator = SequenceToSequenceDataGenerator(raw_scans=False, training=True, \n",
    "                                                        patients=unique_train_patients,\n",
    "                                                        batch_size=batch_size, num_frames_batch=num_frames_batch, \n",
    "                                                        alpha=train_alpha, random_window=random_window, center_crop=True,\n",
    "                                                        img_size_load=img_size_load, img_size_crop=img_size_crop,\n",
    "                                                        dict_ini_features=dict_patients_train_ini_features, \n",
    "                                                        dict_patients_masks_paths=dict_train_patients_masks_paths,\n",
    "                                                        dict_raw_scans_paths=None)\n",
    "    \n",
    "    \n",
    "    df_sub_weights = buildDataSet(unique_train_patients, \n",
    "                 dict_ini_features=dict_patients_train_ini_features, \n",
    "                 dict_seq_weeks=dict_train_sequence_weekssincelastvisit, \n",
    "                 dict_seq_cumweeks=dict_train_sequence_cumweeks, \n",
    "                 training=True, \n",
    "                 predictions=None)\n",
    "   \n",
    "    #################\n",
    "    ## Weights\n",
    "\n",
    "    X_sub_weights = df_sub_weights[features]\n",
    "    y_sub = df_sub_weights['fvc_real'].astype(float)\n",
    "    \n",
    "    y_sub_pred = list_models_weights[n_fold].predict(X_sub_weights)\n",
    "    y_sub_pred_median = unscale(y_sub_pred[:, 1], mean_fvc, std_fvc)\n",
    "    y_sub_pred_std = unscale(y_sub_pred[:, 2], mean_fvc, std_fvc) - unscale(y_sub_pred[:, 0], mean_fvc, std_fvc)\n",
    "\n",
    "    sub_weights_metric = customLossFunction(unscale(y_sub, mean_fvc, std_fvc),\n",
    "                                                    y_sub_pred_median,\n",
    "                                                    y_sub_pred_std).numpy()\n",
    "    \n",
    "    X_sub_last_3 = df_sub_weights.groupby('Patient').tail(3)\n",
    "    y_sub_l3 = X_sub_last_3['fvc_real']\n",
    "    \n",
    "    y_sub_pred_l3 = list_models_weights[n_fold].predict(X_sub_last_3[features])\n",
    "    y_sub_pred_l3_median = unscale(y_sub_pred_l3[:, 1], mean_fvc, std_fvc)\n",
    "    y_sub_pred_l3_std = unscale(y_sub_pred_l3[:, 2], mean_fvc, std_fvc) - unscale(y_sub_pred_l3[:, 0], mean_fvc, std_fvc)\n",
    "    \n",
    "    sub_weights_metric_l3 = customLossFunction(unscale(y_sub_l3, mean_fvc, std_fvc),\n",
    "                                                       y_sub_pred_l3_median,\n",
    "                                                       y_sub_pred_l3_std).numpy()\n",
    "    \n",
    "    print('***'*30)\n",
    "    print(f'Metric sub weights model: {sub_weights_metric}, {sub_weights_metric_l3}')\n",
    "    print('***'*30)\n",
    "    \n",
    "    list_sub_weights_predictions = y_sub_pred_median\n",
    "    list_sub_weights_confidences = y_sub_pred_std\n",
    "    list_sub_weights_predictions_l3 = y_sub_pred_l3_median\n",
    "    list_sub_weights_confidences_l3 = y_sub_pred_l3_std\n",
    "    \n",
    "    #################\n",
    "    ## Base\n",
    "    \n",
    "    list_sub_base_predictions, list_sub_base_confidences = [], []\n",
    "    list_sub_base_predictions_l3, list_sub_base_confidences_l3 = [], []\n",
    "    \n",
    "    for patient in tqdm(unique_train_patients, total=len(unique_train_patients), position=0):\n",
    "        list_submission_weeks_elapsed = dict_train_sequence_fvc[patient]\n",
    "        list_weeks_since_firstvisit = dict_train_sequence_cumweeks[patient]\n",
    "        base_sub_model_predictions, base_sub_model_stds, _, _ = list_models[n_fold].predictEvaluateModel(X_generator=X_sub_generator,\n",
    "                                                         patient=patient, \n",
    "                                                         list_weeks_elapsed=list_submission_weeks_elapsed,\n",
    "                                                         list_weeks_since_firstvisit=list_weeks_since_firstvisit,\n",
    "                                                         initial_fvc=[dict_patients_train_ini_features[patient]['FVC']])\n",
    "        \n",
    "        base_sub_model_predictions = unscale(base_sub_model_predictions.numpy().flatten(), mean_fvc, std_fvc)\n",
    "        list_sub_base_predictions.extend(base_sub_model_predictions)\n",
    "        list_sub_base_confidences.extend(base_sub_model_stds.numpy().flatten())\n",
    "        \n",
    "        list_sub_base_predictions_l3.extend(base_sub_model_predictions[-3:])\n",
    "        list_sub_base_confidences_l3.extend(base_sub_model_stds[-3:].numpy().flatten())\n",
    "        \n",
    "    sub_base_metric = customLossFunction(y_true=unscale(y_sub, mean_fvc, std_fvc),\n",
    "                                               y_pred=list_sub_base_predictions,\n",
    "                                               std=list_sub_base_confidences)\n",
    "    \n",
    "    sub_base_metric_l3 = customLossFunction(y_true=unscale(y_sub_l3, mean_fvc, std_fvc),\n",
    "                                           y_pred=list_sub_base_predictions_l3,\n",
    "                                           std=list_sub_base_confidences_l3)\n",
    "    \n",
    "    print('***'*30)\n",
    "    print(f'Metric sub base model: {sub_base_metric}, {sub_base_metric_l3}')\n",
    "    print('***'*30)\n",
    "    \n",
    "    #################\n",
    "    ## Ensembling\n",
    "    \n",
    "    ensembled_sub_predictions = (np.asarray(list_sub_base_predictions) * ensembled_coeff) + (list_sub_weights_predictions * (1-ensembled_coeff))\n",
    "    ensembled_sub_confidences = (np.asarray(list_sub_base_confidences) * ensembled_coeff) + (list_sub_weights_confidences * (1-ensembled_coeff))\n",
    "    \n",
    "    ensembled_sub_predictions_l3 = (np.asarray(list_sub_base_predictions_l3) * ensembled_coeff) + (list_sub_weights_predictions_l3 * (1-ensembled_coeff))\n",
    "    ensembled_sub_confidences_l3 = (np.asarray(list_sub_base_confidences_l3) * ensembled_coeff) + (list_sub_weights_confidences_l3 * (1-ensembled_coeff))\n",
    "    \n",
    "    sub_metric_ensembled = customLossFunction(y_true=unscale(y_sub, mean_fvc, std_fvc),\n",
    "                                           y_pred=ensembled_sub_predictions,\n",
    "                                           std=ensembled_sub_confidences)\n",
    "    \n",
    "    sub_metric_ensembled_l3 = customLossFunction(y_true=unscale(y_sub_l3, mean_fvc, std_fvc),\n",
    "                                             y_pred=ensembled_sub_predictions_l3,\n",
    "                                             std=ensembled_sub_confidences_l3)\n",
    "    \n",
    "    print('***'*30)\n",
    "    print(f'Metric ensembled model: {sub_metric_ensembled}, {sub_metric_ensembled_l3}')\n",
    "    print('***'*30)\n",
    "    \n",
    "    #################\n",
    "    \n",
    "    list_base_h.append({'metric' : sub_base_metric, 'Metrict3Timesteps' : sub_base_metric_l3})\n",
    "    list_weights_h.append({'metric' : sub_weights_metric, 'Metrict3Timesteps' : sub_weights_metric_l3})\n",
    "    list_ensembled_h.append({'metric' : sub_metric_ensembled, 'Metrict3Timesteps' : sub_metric_ensembled_l3})\n",
    "    \n",
    "\n",
    "#################\n",
    "\n",
    "\n",
    "base_sub_metric = np.mean([(history['metric']) for history in list_base_h])\n",
    "base_sub_metric_last3 = np.mean([(history['Metrict3Timesteps']) for history in list_base_h])\n",
    "\n",
    "print(base_sub_metric, base_sub_metric_last3)\n",
    "\n",
    "## Weights\n",
    "\n",
    "weights_sub_metric = np.mean([(history['metric']) for history in list_weights_h])\n",
    "weights_sub_metric_last3 = np.mean([(history['Metrict3Timesteps']) for history in list_weights_h])\n",
    "\n",
    "print(weights_sub_metric, weights_sub_metric_last3)\n",
    "\n",
    "## Ensemble\n",
    "\n",
    "ensemble_sub_metric = np.mean([(history['metric']) for history in list_ensembled_h])\n",
    "ensemble_sub_metric_last3 = np.mean([(history['Metrict3Timesteps']) for history in list_ensembled_h])\n",
    "\n",
    "print(ensemble_sub_metric, ensemble_sub_metric_last3)\n",
    "\n",
    "#################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
