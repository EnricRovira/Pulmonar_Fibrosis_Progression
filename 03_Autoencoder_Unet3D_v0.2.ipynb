{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder 3D-UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 01. Libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "\n",
    "import tensorflow as tf\n",
    "# To allocate memory dynamically\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "tf.config.experimental.enable_mlir_graph_optimization()\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, regularizers\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "import time\n",
    "from Utils.utils import *\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 02. Global Variables\n",
    "\n",
    "path = '../01_Data/'\n",
    "path_models = '../05_Saved_Models/'\n",
    "\n",
    "path_train_masks = path + '/train_masks/'\n",
    "path_test_masks = path + '/test_masks/'\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 29295.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 -> There are 176 train unique patients\n",
      "1.2 -> There are 5 test unique patients\n",
      "No. of Train Masks : 176\n",
      "No. of Test Masks : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# 03. Load Data & Preprocess Data\n",
    "\n",
    "df_train = pd.read_csv( path + 'train.csv')\n",
    "df_test = pd.read_csv(path + 'test.csv')\n",
    "\n",
    "print(f'1.1 -> There are {df_train.Patient.unique().shape[0]} train unique patients')\n",
    "print(f'1.2 -> There are {df_test.Patient.unique().shape[0]} test unique patients')\n",
    "\n",
    "train_mask_paths = glob.glob(path_train_masks + '*')\n",
    "test_mask_paths = glob.glob(path_test_masks + '*')\n",
    "\n",
    "print(f'No. of Train Masks : {len(train_mask_paths)}')\n",
    "print(f'No. of Test Masks : {len(test_mask_paths)}')\n",
    "      \n",
    "unique_train_patients = df_train.Patient.unique()\n",
    "unique_test_patients = df_test.Patient.unique()\n",
    "\n",
    "dict_train_patients_masks_paths = {patient: path_train_masks + patient + '/' for patient in unique_train_patients}\n",
    "dict_test_patients_masks_paths = {patient: path_test_masks + patient + '/' for patient in unique_test_patients}\n",
    "\n",
    "for patient in tqdm(dict_train_patients_masks_paths):\n",
    "    if os.path.exists(dict_train_patients_masks_paths[patient]):\n",
    "        list_files = os.listdir(dict_train_patients_masks_paths[patient])\n",
    "        list_files = [dict_train_patients_masks_paths[patient] + file for file in list_files]\n",
    "        dict_train_patients_masks_paths[patient] = list_files\n",
    "    \n",
    "for patient in tqdm(dict_test_patients_masks_paths):\n",
    "    list_files = os.listdir(dict_test_patients_masks_paths[patient])\n",
    "    list_files = [dict_test_patients_masks_paths[patient] + file for file in list_files]\n",
    "    dict_test_patients_masks_paths[patient] = list_files\n",
    "    \n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 05. Classes\n",
    "\n",
    "## 04.1 Generator\n",
    "\n",
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, training, df, batch_size=1, num_frames_batch=32, \n",
    "                 alpha=1.0, random_window=False, center_crop=True,\n",
    "                 img_size_load=(500, 500, 3), \n",
    "                 img_size_crop=(440, 440, 3)):\n",
    "        super(ImageDataGenerator, self).__init__()\n",
    "        self.training = training\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.num_frames_batch = num_frames_batch\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.random_window = random_window\n",
    "        self.center_crop = center_crop\n",
    "        self.img_size_load = img_size_load\n",
    "        self.img_size_crop = img_size_crop\n",
    "        \n",
    "        self.dict_train_patients_masks_paths = dict_train_patients_masks_paths\n",
    "        self.dict_test_patients_masks_paths = dict_test_patients_masks_paths\n",
    "        \n",
    "        self.ids = list(self.df['Patient'].unique())\n",
    "\n",
    "        self.num_steps = int(np.ceil(len(self.ids) / self.batch_size))\n",
    "        self.on_epoch_end()\n",
    "      \n",
    "    # Number of batches in the sequence\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_steps\n",
    "    \n",
    "    \n",
    "    # Gets the batch at position index, return patient images and dict ini features\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        patient_ids = [self.ids[k] for k in indexes]\n",
    "        list_scan_imgs = [decodePatientImages(patient,\n",
    "                                              self.dict_train_patients_masks_paths,\n",
    "                                              image_size=(self.img_size_load[0], self.img_size_load[1]), \n",
    "                                              numpy=True) \n",
    "                          for patient in patient_ids]\n",
    "        patient_imgs = self.groupImages(list_scan_imgs)\n",
    "        patient_imgs = self.loadImagesAugmented(patient_imgs)\n",
    "        return patient_imgs, patient_imgs\n",
    "    \n",
    "    \n",
    "    def filterSlices(self, array_imgs):\n",
    "        num_patient_slices = array_imgs.shape[0]\n",
    "        beta = int(self.alpha * num_patient_slices)\n",
    "        if beta % 2 != 0:\n",
    "            beta += 1\n",
    "        if num_patient_slices > self.num_frames_batch:\n",
    "            if beta > self.num_frames_batch and self.alpha < 1:\n",
    "                remove = int((num_patient_slices - beta)/2)\n",
    "                array_imgs = array_imgs[remove:, :, :, :]\n",
    "                array_imgs = array_imgs[:-remove:, :, :]\n",
    "\n",
    "        return array_imgs\n",
    "    \n",
    "    def frameSkipImages(self, patient_imgs):\n",
    "        num_patient_slices = patient_imgs.shape[0]\n",
    "        frame_skip = num_patient_slices // self.num_frames_batch\n",
    "        skipped_patient_imgs = np.zeros((self.num_frames_batch, self.img_size_load[0], self.img_size_load[1], 1))\n",
    "        for i in range(self.num_frames_batch):\n",
    "            skipped_patient_imgs[i] = patient_imgs[i*frame_skip]    \n",
    "        return skipped_patient_imgs\n",
    "    \n",
    "    \n",
    "    def randomWindow(self, patient_imgs):\n",
    "        windowed_imgs = np.zeros((self.num_frames_batch, patient_imgs.shape[1], patient_imgs.shape[2], 1))\n",
    "        num_frames = patient_imgs.shape[0]\n",
    "        if num_frames < self.num_frames_batch:\n",
    "            windowed_imgs[:num_frames] = patient_imgs\n",
    "        else:\n",
    "            random_frames = np.arange(num_frames)\n",
    "            index = np.random.randint(0, num_frames - self.num_frames_batch)\n",
    "            windowed_imgs[0:] = patient_imgs[index:index+self.num_frames_batch]\n",
    "        return windowed_imgs\n",
    "            \n",
    "        \n",
    "    def groupImages(self, list_scan_imgs):\n",
    "        grouped_imgs = []\n",
    "        for patient_imgs in list_scan_imgs:\n",
    "            if patient_imgs.shape[1] > self.num_frames_batch:\n",
    "                patient_imgs = self.filterSlices(patient_imgs)\n",
    "            if self.random_window:\n",
    "                patient_imgs = self.randomWindow(patient_imgs)\n",
    "            else:\n",
    "                patient_imgs = self.frameSkipImages(patient_imgs)\n",
    "            grouped_imgs.append(patient_imgs)\n",
    "        return np.asarray(grouped_imgs)\n",
    "        \n",
    "        \n",
    "    def loadImagesAugmented(self, patient_imgs):\n",
    "        # (bs, numframesbatch, image_load0, image_load1, 1)\n",
    "\n",
    "        if self.img_size_load != self.img_size_crop:\n",
    "            patient_imgs = self.center3Dcropping(patient_imgs)\n",
    "            patient_imgs = self.random3DCropping(patient_imgs)\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = np.fliplr(patient_imgs)\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = np.flipud(patient_imgs)\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = patient_imgs[:, :, ::-1]\n",
    "        if self.training and np.random.random() > 0.5:\n",
    "            patient_imgs = patient_imgs[:, ::-1, :]\n",
    "        if self.training:\n",
    "            patient_rotated_imgs= []\n",
    "            for batch in range(patient_imgs.shape[0]):\n",
    "                angle = np.random.randint(-15, 15)\n",
    "                batch_imgs_rotated = np.asarray([ndimage.rotate(patient_imgs[batch, i], angle,\n",
    "                                                                reshape=False) for i in range(patient_imgs.shape[1])])\n",
    "                patient_rotated_imgs.append(batch_imgs_rotated)\n",
    "            patient_imgs = np.asarray(patient_rotated_imgs) \n",
    "        return patient_imgs\n",
    "    \n",
    "    \n",
    "    def random3DCropping(self, patient_imgs):\n",
    "        w, h = self.img_size_crop[0], self.img_size_crop[1]\n",
    "        x = np.random.randint(0, patient_imgs.shape[2] - w)\n",
    "        y = np.random.randint(0, patient_imgs.shape[2] - h)\n",
    "        patient_crop_imgs = patient_imgs[:, :, y:y+h, x:x+w]\n",
    "        return patient_crop_imgs\n",
    "    \n",
    "    \n",
    "    def center3Dcropping(self, patient_imgs):\n",
    "        w, h = patient_imgs.shape[2] - 20, patient_imgs.shape[3] - 20\n",
    "        img_height, img_width = patient_imgs.shape[2], patient_imgs.shape[3]\n",
    "        left, right = (img_width - w) / 2, (img_width + w) / 2\n",
    "        top, bottom = (img_height - h) / 2, (img_height + h) / 2\n",
    "        left, top = round(max(0, left)), round(max(0, top))\n",
    "        right, bottom = round(min(img_width - 0, right)), round(min(img_height - 0, bottom))\n",
    "        patient_crop_imgs = patient_imgs[:, :, top:bottom, left:right]\n",
    "        return patient_crop_imgs\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.ids))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        \n",
    "        \n",
    "    def getOnePatient(self, patient_id):\n",
    "        list_scan_imgs = [decodePatientImages(patient_id,\n",
    "                                              self.dict_train_patients_masks_paths,\n",
    "                                              image_size=(self.img_size_load[0], self.img_size_load[1]),\n",
    "                                              numpy=True)] \n",
    "        patient_imgs = self.groupImages(list_scan_imgs)\n",
    "        patient_imgs = self.loadImagesAugmented(patient_imgs)\n",
    "        return patient_imgs, patient_imgs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 06. Model\n",
    "\n",
    "def unet3d(input_shape=(None, None, None, 1)):\n",
    "\n",
    "    input_im = layers.Input(shape=input_shape)\n",
    "    \n",
    "    avg_input = layers.AveragePooling3D((2, 1, 1))(input_im)\n",
    "    \n",
    "    conv1b = layers.Conv3D(filters=32, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(avg_input)\n",
    "    batch_norm1b = layers.BatchNormalization()(conv1b)\n",
    "    activ1b = layers.Activation('relu')(batch_norm1b)\n",
    "    maxpool1 = layers.MaxPooling3D((2, 2, 2))(activ1b)\n",
    "    \n",
    "    conv2a = layers.Conv3D(filters=64, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(maxpool1)\n",
    "    batch_norm2a = layers.BatchNormalization()(conv2a)\n",
    "    activ2a = layers.Activation('relu')(batch_norm2a)\n",
    "    conv2b = layers.Conv3D(filters=64, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(activ2a)\n",
    "    batch_norm2b = layers.BatchNormalization()(conv2b)\n",
    "    activ2b = layers.Activation('relu')(batch_norm2b)\n",
    "    maxpool2 = layers.MaxPooling3D((2, 2, 2))(activ2b)\n",
    "    \n",
    "    conv3a = layers.Conv3D(filters=128, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(maxpool2)\n",
    "    batch_norm3a = layers.BatchNormalization()(conv3a)\n",
    "    activ3a = layers.Activation('relu')(batch_norm3a)\n",
    "    conv3b = layers.Conv3D(filters=128, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(activ3a)\n",
    "    batch_norm3b = layers.BatchNormalization()(conv3b)\n",
    "    activ3b = layers.Activation('relu')(batch_norm3b)\n",
    "    maxpool3 = layers.MaxPooling3D((2, 2, 2))(activ3b)\n",
    "    \n",
    "    conv4b = layers.Conv3D(filters=256, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-3))(maxpool3)\n",
    "    batch_norm4b = layers.BatchNormalization()(conv4b)\n",
    "    activ4b = layers.Activation('relu')(batch_norm4b)\n",
    "    up_conv4b = layers.UpSampling3D((2, 2, 2))(activ4b)\n",
    "    \n",
    "    concat1 = layers.concatenate([up_conv4b, activ3b])\n",
    "    \n",
    "    conv5a = layers.Conv3D(filters=128, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(concat1)\n",
    "    batch_norm5a = layers.BatchNormalization()(conv5a)\n",
    "    activ5a = layers.Activation('relu')(batch_norm5a)\n",
    "    conv5b = layers.Conv3D(filters=128, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(activ5a)\n",
    "    batch_norm5b = layers.BatchNormalization()(conv5b)\n",
    "    activ5b = layers.Activation('relu')(batch_norm5b)\n",
    "    up_conv5b = layers.UpSampling3D((2, 2, 2))(activ5b)\n",
    "    \n",
    "    concat2 = layers.concatenate([up_conv5b, activ2b])\n",
    "    \n",
    "    conv6a = layers.Conv3D(filters=64, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(concat2)\n",
    "    batch_norm6a = layers.BatchNormalization()(conv6a)\n",
    "    activ6a = layers.Activation('relu')(batch_norm6a)\n",
    "    conv6b = layers.Conv3D(filters=64, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(activ6a)\n",
    "    batch_norm6b = layers.BatchNormalization()(conv6b)\n",
    "    activ6b = layers.Activation('relu')(batch_norm6b)\n",
    "    up_conv6b = layers.UpSampling3D((2, 2, 2))(activ6b)\n",
    "    \n",
    "    concat3 = layers.concatenate([up_conv6b, activ1b])\n",
    "    \n",
    "    conv7b = layers.Conv3D(filters=32, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(concat3)\n",
    "    batch_norm7b = layers.BatchNormalization()(conv7b)\n",
    "    activ7b = layers.Activation('relu')(batch_norm7b)\n",
    "    \n",
    "    up_conv_out = layers.UpSampling3D((2, 1, 1))(activ7b)\n",
    "    \n",
    "    conv_out = layers.Conv3D(filters=1, kernel_size=3, padding='same', kernel_regularizer=regularizers.l2(1e-4))(up_conv_out)\n",
    "    batch_norm_out = layers.BatchNormalization()(conv_out)\n",
    "    activ_out = layers.Activation('relu')(batch_norm_out)\n",
    "    \n",
    "    model = models.Model(inputs=input_im, outputs=activ_out, name='UNET3D')\n",
    "    encoder_model = models.Model(inputs=input_im, outputs=activ4b, name='encoder_UNET3D')\n",
    "\n",
    "    return model, encoder_model\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 07. Model Training\n",
    "\n",
    "img_size_load=(200, 200, 1)\n",
    "img_size_crop=(160, 160, 1)\n",
    "num_frames_batch = 32\n",
    "alpha = 0.9\n",
    "batch_size = 1\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "df_X_train, df_X_val = getTrainValidation(df_train, df_test)\n",
    "\n",
    "\n",
    "X_train_img_generator = ImageDataGenerator(\n",
    "                             training=True, df=df_X_train,\n",
    "                             batch_size=batch_size, num_frames_batch=num_frames_batch, \n",
    "                             alpha=alpha, random_window=True, center_crop=True,\n",
    "                             img_size_load=img_size_load, img_size_crop=img_size_crop)\n",
    "\n",
    "X_val_img_generator = ImageDataGenerator(\n",
    "                             training=False, df=df_X_val,\n",
    "                             batch_size=1, num_frames_batch=num_frames_batch, \n",
    "                             alpha=alpha, random_window=True, center_crop=True,\n",
    "                             img_size_load=img_size_load, img_size_crop=img_size_crop)\n",
    "\n",
    "# autoencoder_3d, encoder = unet3d(input_shape=(32, 160, 160, 1))\n",
    "autoencoder_3d, encoder = unet3d(input_shape=(None, None, None, 1))\n",
    "\n",
    "optimizer=optimizers.Adam(learning_rate=0.0002)\n",
    "optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(optimizer)\n",
    "\n",
    "autoencoder_3d.compile(loss=tf.keras.losses.MeanSquaredError(), \n",
    "                       optimizer=optimizer)\n",
    "\n",
    "# print(autoencoder_3d.summary(120))\n",
    "\n",
    "history = autoencoder_3d.fit(\n",
    "    X_train_img_generator,\n",
    "    validation_data=X_val_img_generator,\n",
    "    epochs=1,\n",
    "    verbose=1\n",
    ") \n",
    "\n",
    "plotTrainHistory(history.history, title='Autoencoder Training', scale=False)\n",
    "    \n",
    "# tf.keras.models.save_model(model=encoder, filepath=path_models + 'encoder_unet3d.h5', include_optimizer=False)\n",
    "\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 08. Imgs Reconstruction\n",
    "\n",
    "patient = np.random.choice(list(df_train['Patient'].unique()))\n",
    "print(f'Patient: {patient}')\n",
    "\n",
    "patient_imgs = X_val_img_generator.getOnePatient(patient)[0]\n",
    "patient_imgs_reconstrcuted = autoencoder_3d.predict(patient_imgs)\n",
    "\n",
    "for i in range(patient_imgs.shape[1]):\n",
    "    print(i)\n",
    "    print('Original')\n",
    "    plt.imshow(patient_imgs[0, i].squeeze(), 'gray')\n",
    "    plt.show()\n",
    "    print('Reconstructed')\n",
    "    plt.imshow(patient_imgs_reconstrcuted[0, i].squeeze(), 'gray')\n",
    "    plt.show()\n",
    "    print('==='*20)\n",
    "    \n",
    "#########################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
